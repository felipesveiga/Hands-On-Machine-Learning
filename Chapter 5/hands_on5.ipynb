{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8174a113-5bc3-4ba1-b962-fce10611cf81",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'> Support Vector Machines</h1>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            As SVM's são um dos modelos mais populares de ML. São frequentemente utilizadas em tarefas de classificação de datasets complexos com pequeno ou médio tamanho. Por outro lado, é possível fazer regressões e até mesmo detecção de outliers com elas.\n",
    "        </li>\n",
    "        <li> \n",
    "            Nota: sempre normalize os dados quando for trabalhar com SVM's.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a49b04f-a5b5-4dd3-89c4-be3f713cace6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2 style='font-size:30px'> Linear SVM Classification</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "           As SVM's com o kernel linear são apropriadas para a segregação de dados linearmente distinguíveis.\n",
    "        </li>\n",
    "        <li> \n",
    "            Na imagem da esquerda, as linhas sólidas representam dois modelos de classificação. Apesar de identificarem corretamente todas as instâncias de treino, note que elas estão muito próximas dos pontos. Isso é um indicativo de que os modelos foram excessivamente adequados a esses dados -possivelmente um overfitting- e que eles falharão em corretamente classificar novas instâncias.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<img src='svm_linear1.png'>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "           No entanto, observe que a linha da imagem à direita (de um SVM Linear) não só gabarita a classificação, como também está bem afastada dos pontos. Isso nos dá uma segurança muito maior de que novos dados serão corretamente classificados.\n",
    "        </li>\n",
    "        <li> \n",
    "            A intenção da linha é estar o mais distante possível das instâncias de treino. Os pontos mais próximos (circulados) são denominados como support vectors.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ad6015-d710-43ab-8347-9b052f037991",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'>Soft-Margin Classification</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "           Mas vamos ser honestos. É muito difícil haver um dataset cujas categorias sejam linearmente distinguíveis. Como consequência desse fato, ter um SVM como o da imagem à direita é algo improvável; o modelo provavelmente terá que tolerar que algumas instâncias estejam no lado errado.\n",
    "        </li>\n",
    "        <li> \n",
    "            É considerando isso que é praticada a Soft-Margin Classification. Uma SVM voltada a esse tipo de tarefa precisa ter uma baixa regularização.\n",
    "        </li>\n",
    "        <li> \n",
    "            A regularização de uma SVM é controlada pelo argumento C. Quanto menor, menos regularização.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f62e3-e9fd-44ab-8ea2-e5cc52b19421",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <h1>Exemplos de SVM com Soft-Margin Classification</h1>\n",
    "    <img src='svm_linear2.png'>\n",
    "</center>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "          Claramente o modelo à esquerda parece ser o mais apropriado\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28722e86-1d2b-43ed-a434-67d815ceeded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Montando uma SVM linear para o dataset de iris.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data'][:, 2:]\n",
    "y = (iris['target']==2).astype('int')\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('linear_svc', LinearSVC(C=1, loss='hinge'))])\n",
    "svm_clf.fit(X,y)\n",
    "svm_clf.predict([[5.5, 1.7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2c8d46-c29b-4ecf-81a1-b429beb57699",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "              Seria possível usarmos o objecto SVC com o kernel='linear', mas ele é muito mais lento do que o LinearSVC.\n",
    "        </li>\n",
    "        <li> \n",
    "            Se quiséssemos usar um Stochastic Gradient Descent para o encontro da reta, poderíamos usar o SGDClassifier(loss='hinge', alpha=1/(m*C)). É bastante recomendável para datasets gigantescos.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8333d12-ae0a-428a-95cb-06fddf269937",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'>Dicas</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "           Para LinearSVC, é recomendável usar o StandardScaler com o dataset. Defina também loss='hinge'. Sette dual=False a não ser que haja mais features do que instâncias de treino.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2c0ff1-b4c3-484d-8175-2c934cd1a8e6",
   "metadata": {},
   "source": [
    "<p style='color:red'> Soft-Margin Classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
