{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8174a113-5bc3-4ba1-b962-fce10611cf81",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'> Support Vector Machines</h1>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            As SVM's são um dos modelos mais populares de ML. São frequentemente utilizadas em tarefas de classificação de datasets complexos com pequeno ou médio tamanho. Por outro lado, é possível fazer regressões e até mesmo detecção de outliers com elas.\n",
    "        </li>\n",
    "        <li> \n",
    "            Nota: sempre normalize os dados quando for trabalhar com SVM's.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a49b04f-a5b5-4dd3-89c4-be3f713cace6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2 style='font-size:30px'> Linear SVM Classification</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "           As SVM's com o kernel linear são apropriadas para a segregação de dados linearmente distinguíveis.\n",
    "        </li>\n",
    "        <li> \n",
    "            Na imagem da esquerda, as linhas sólidas representam dois modelos de classificação. Apesar de identificarem corretamente todas as instâncias de treino, note que elas estão muito próximas dos pontos. Isso é um indicativo de que os modelos foram excessivamente adequados a esses dados -possivelmente um overfitting- e que eles falharão em corretamente classificar novas instâncias.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<img src='svm_linear1.png'>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "           No entanto, observe que a linha da imagem à direita (de um SVM Linear) não só gabarita a classificação, como também está bem afastada dos pontos. Isso nos dá uma segurança muito maior de que novos dados serão corretamente classificados.\n",
    "        </li>\n",
    "        <li> \n",
    "            A intenção da linha é estar o mais distante possível das instâncias de treino. Os pontos mais próximos (circulados) são denominados como support vectors.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ad6015-d710-43ab-8347-9b052f037991",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'>Soft-Margin Classification</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "           Mas vamos ser honestos. É muito difícil haver um dataset cujas categorias sejam linearmente distinguíveis. Como consequência desse fato, ter um SVM como o da imagem à direita é algo improvável; o modelo provavelmente terá que tolerar que algumas instâncias estejam no lado errado.\n",
    "        </li>\n",
    "        <li> \n",
    "            É considerando isso que é praticada a Soft-Margin Classification. Uma SVM voltada a esse tipo de tarefa precisa ter uma baixa regularização.\n",
    "        </li>\n",
    "        <li> \n",
    "            A regularização de uma SVM é controlada pelo argumento C. Quanto menor, mais regularização.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f62e3-e9fd-44ab-8ea2-e5cc52b19421",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <h1>Exemplos de SVM com Soft-Margin Classification</h1>\n",
    "    <img src='svm_linear2.png'>\n",
    "</center>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "          Claramente o modelo à esquerda parece ser o mais apropriado\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28722e86-1d2b-43ed-a434-67d815ceeded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Montando uma SVM linear para o dataset de iris.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data'][:, 2:]\n",
    "y = (iris['target']==2).astype('int')\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('linear_svc', LinearSVC(C=1, loss='hinge'))])\n",
    "svm_clf.fit(X,y)\n",
    "svm_clf.predict([[5.5, 1.7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2c8d46-c29b-4ecf-81a1-b429beb57699",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "              Seria possível usarmos o objecto SVC com o kernel='linear', mas ele é muito mais lento do que o LinearSVC.\n",
    "        </li>\n",
    "        <li> \n",
    "            Se quiséssemos usar um Stochastic Gradient Descent para o encontro da reta, poderíamos usar o SGDClassifier(loss='hinge', alpha=1/(m*C)). É bastante recomendável para datasets gigantescos.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8333d12-ae0a-428a-95cb-06fddf269937",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'>Dicas</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "           Para LinearSVC, é recomendável usar o StandardScaler com o dataset. Defina também loss='hinge'. Sette dual=False a não ser que haja mais features do que instâncias de treino.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0781789a-e192-4eb5-8447-af9f385a10fa",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Nonlinear SVM Classification</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "          Além dos ajustes de regularização,  um outro recurso para lidar com dados não linearmente distinguíveis é utilizar \"PolynomialFeatures\" sobre eles.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c939fd3-5cb0-4d55-9922-09b01623a70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7f3248141760>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Observe, as duas classes, com uma única feature, não são linearmente distinguíveis.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "class_1 =np.array([-2,-1,0,1,2])\n",
    "class_2= np.array([-4,-3,3,4])\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.scatter(class_1, [0,0,0,0,0])\n",
    "plt.scatter(class_2,[0,0,0,0])\n",
    "\n",
    "# Mas veja, basta adicionarmos o quadrado da primeira feature (x^2) como uma nova característica que a segregação é possível.\n",
    "plt.subplot(122)\n",
    "plt.scatter(class_1, class_1**2)\n",
    "plt.scatter(class_2, class_2**2)\n",
    "plt.axhline(6, ls='--', lw=1,color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfc15d37-cbe5-433a-be38-bbfa7ed51f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/veiga/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agora, vamos utilizar, de fato, o PolynomialFeatures.\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "X,y = make_moons()\n",
    "polynomial_svm_clf = Pipeline([\n",
    "            ('poly_features', PolynomialFeatures(degree=3)),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('svm_clf', LinearSVC(C=10, loss='hinge'))])\n",
    "\n",
    "polynomial_svm_clf.fit(X,y)\n",
    "polynomial_svm_clf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b58c0d-caf2-40ab-80d8-bfad2950aa71",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <h1> Fronteiras de Decisão de um SVM Polinomial</h1>\n",
    "    <img src='poly_svm1.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6795cfdc-5009-4b9c-960d-8ab81cd4b268",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Polynomial Kernel</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O kernel polinomial do objeto SVC produz uma espécie de truque matemático: ele permite que nós obtenhamos a mesma previsão que seria tida ao se aplicar PolynomialFeatures, mesmo sem isso de fato ocorrer. Com isso, o dataset é mantido com as mesmas proporções iniciais.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "508130d7-ada2-441e-a10a-6216b6b7bd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('svm_clf', SVC(C=5, coef0=1, kernel='poly'))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando o SVC 'poly' com o make_moons.\n",
    "\n",
    "# Apenas tenha cautela ao se definir 'degree', o risco de overfit aumenta conforme o seu valor cresce.\n",
    "\n",
    "# 'coef0' define o quanto o modelo será influenciado por degrees elevados em comparação com os baixos.\n",
    "from sklearn.svm import SVC\n",
    "poly_kernel_svm_clf = Pipeline([\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('svm_clf', SVC(kernel='poly', degree=3, C=5, coef0=1))])\n",
    "poly_kernel_svm_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c2275a-383c-4ca0-9132-8898f72847e5",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Adding Similarity Features</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Outra maneira de criarmos novas features é usando a RBF (Radial Basis Function) Gaussiana. São utilizadas as distâncias de cada feature a <em> landmarks</em> (pontos arbitrários no plano cartesiano) específcos.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<center> \n",
    "    <img src='rbf1.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4c19b4-b97d-4571-8b9b-5cf8a9b01af6",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Gaussian RBF Kernel</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O problema de se aplicar essa fórmula diretamente no dastaset é que ele sofrerá um aumento de volume considerável.\n",
    "        </li>\n",
    "        <li> \n",
    "            Considerando isso, o objeto SVC é capaz de fazer mais um truque matemático com o kernel 'rbf'. Vamos obter previsões similares as de se tivéssemos adicionado as similarity features sem tendo, de fato, o feito.\n",
    "        </li>\n",
    "        <li> \n",
    "            Este kernel, assim como outros do objeto SVC, contam com o parâmetro \"gamma\". Esse, de maneira similar a \"C\", controla a regularização, só que de forma mais aguda - por isso, tenha bastante cautela ao definir o seu valor.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45dcc807-73eb-49a8-92c2-1baed21ef47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('svm_clf', SVC(C=0.001, gamma=5))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Montando um SVC de kernel 'rbf'.\n",
    "rbf_kernel_svm_clf = Pipeline([\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('svm_clf', SVC(kernel='rbf', gamma=5, C=1e-3))])\n",
    "\n",
    "rbf_kernel_svm_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2c0ff1-b4c3-484d-8175-2c934cd1a8e6",
   "metadata": {},
   "source": [
    "<p style='color:red'> Computational Complexity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
