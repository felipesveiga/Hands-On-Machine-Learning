{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9bd146-d458-49fe-a33e-c432ddd18ec3",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'> Custom Models and Training with TensorFlow</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e16877-5c58-47cd-b034-c461ae8b360c",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Exploraremos as outras funcionalidades contidas no TensorFlow. Seu ecossistema possui módulos para tratar os mais diversos problemas do Machine Learning. Segue o diagrama apresentado pelo livro:\n",
    "            <center style='margin-top:10px'> \n",
    "                <img src='tf_diag.png'>\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d521d7e-aee9-44f6-abc7-85c53cd49893",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Using TensorFlow Like Numpy</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O TensorFlow contém funcionalidades muito próximas das do numpy. No caso, somos capazes de criar tensores (espécies de matrizes) e executar certas operações matemáticas.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39abffd3-189c-4465-982c-8a50bf8ae170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-21 13:23:06.964082: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /u01/app/oracle/product/11.2.0/xe/lib:/lib:/usr/local/lib:\n",
      "2023-01-21 13:23:06.964116: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-21 13:23:10.910066: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /u01/app/oracle/product/11.2.0/xe/lib:/lib:/usr/local/lib:\n",
      "2023-01-21 13:23:10.910093: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-21 13:23:10.910119: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (veiga-Inspiron): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5]], dtype=int32)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando um tensor com `tf.constant`.\n",
    "\n",
    "# A particularidade desse objeto é a sua imutabilidade (não pode ser alterado in-place).\n",
    "import tensorflow as tf\n",
    "tf.constant(range(6), shape=(3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0f36d44-0488-4857-baeb-28b1d31bc91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=23>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Os tensores admitem receberem números soltos também.\n",
    "tf.constant(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c038638a-f613-4c53-a37d-e4e95ec1a006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.sqrt: [[0.    1.    1.414]\n",
      " [1.732 2.    2.236]\n",
      " [2.45  2.646 2.828]\n",
      " [3.    3.162 3.316]]\n",
      "\n",
      "L2: [11.23  12.88  14.625]\n"
     ]
    }
   ],
   "source": [
    "# A maior parte das funções do Numpy também são encontradas no TF. Essas podem ter nomes um pouco distintos, ou ainda estarem\n",
    "# dentro do módulo `tensorflow.math`.\n",
    "t = tf.constant(range(12), dtype=tf.float16, shape=(4,3))\n",
    "print(f'tf.sqrt: {tf.sqrt(t)}', end='\\n\\n')\n",
    "\n",
    "# A norma l-2 é encontrada no em `math`.\n",
    "from tensorflow.math import reduce_euclidean_norm\n",
    "print(f'L2: {reduce_euclidean_norm(t, axis=0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb75fbf6-0f90-4dbf-be39-a6299d321392",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Keras' Low-Level API</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             O Keras também contém certas funcionalidades voltadas à manipulação de matrizes em <em> keras.backend</em>. É útil usá-lo quando queremos que haja portabilidade de nosso código com outras implementações Keras.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fef9698e-b7e0-4775-843b-89fa6875c9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float16, numpy=\n",
       "array([[  0.,   1.,   4.],\n",
       "       [  9.,  16.,  25.],\n",
       "       [ 36.,  49.,  64.],\n",
       "       [ 81., 100., 121.]], dtype=float16)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# É costumaz se referir ao módulo como 'K'.\n",
    "import tensorflow.keras.backend as K\n",
    "K.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571860d8-9fa3-4caa-ba60-e700a4485828",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Tensors and NumPy</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Tensores TF podem se originar a partir de arrays do numpy e vice-versa.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3206b0da-f385-4302-8f3e-5308ff4f5de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conseguimos, inclusive, aplicar funções do numpy diretamente em tensores!\n",
    "import numpy as np\n",
    "np.linalg.norm(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0ad002f-416a-4891-bc09-c5a6247a60d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando um tensor com um array.\n",
    "a = np.arange(10)\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b784a-f672-4ff3-9eb0-a14c2d14d66d",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Type Conversions</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Diferentemente do numpy, o TensorFlow não faz adaptações de data types em seus procedimentos. Isso significa que manipular um array de integer com um de float, por exemplo, resultará em erro.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6adabd58-12e6-4567-827a-3862e641283b",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute AddV2 as input #1(zero-based) was expected to be a half tensor but is a float tensor [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_187225/1444564877.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 'float16'+ 'float32'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7162\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7163\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7164\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute AddV2 as input #1(zero-based) was expected to be a half tensor but is a float tensor [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "t2 = tf.constant(range(10, 22), shape=(4,3), dtype=tf.float32)\n",
    "\n",
    "# 'float16'+ 'float32'.\n",
    "t+t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdc3d806-702f-4185-aaa8-05ec969ac7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float16, numpy=\n",
       "array([[10., 12., 14.],\n",
       "       [16., 18., 20.],\n",
       "       [22., 24., 26.],\n",
       "       [28., 30., 32.]], dtype=float16)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use `cast` para alterar o data type do tensor.\n",
    "t + tf.cast(t2, tf.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31df0fd-d9a4-4f19-83e5-945ab2221c5e",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Variables</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            <em>tf.variable</em> é também um tensor, mas que admite alterações in-place.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cc864dd-768f-4dff-8f6b-6732255fb2df",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(4, 4) dtype=float32, numpy=\n",
       "array([[ 1.,  2.,  3.,  4.],\n",
       "       [ 2.,  4.,  6.,  8.],\n",
       "       [ 3.,  6.,  9., 12.],\n",
       "       [ 4.,  8., 12., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando uma variável.\n",
    "v = tf.Variable([[i*a for i in range(1,5)] for a in range(1,5)], dtype=tf.float32)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "949998b6-1138-42a1-ac5b-268d6da170d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(4, 4) dtype=float32, numpy=\n",
       "array([[ 1., 20.,  3.,  4.],\n",
       "       [ 2.,  4.,  6.,  8.],\n",
       "       [ 3.,  6.,  9., 12.],\n",
       "       [ 4.,  8., 12., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usando `assign` para modificar a posição [0,1].\n",
    "v[0,1].assign(20)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c42758e4-956c-48dc-89cf-8d6ffd7323e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(4, 4) dtype=float32, numpy=\n",
       "array([[  1.,  20.,   3.,   4.],\n",
       "       [  2., 100.,   6.,   8.],\n",
       "       [  3.,   6.,   9.,  12.],\n",
       "       [  4.,   8., 200.,  16.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `scatter_nd_update` modifica múltiplos elementos de uma só vez.\n",
    "v.scatter_nd_update(indices=[[1,1], [3,2]], updates=[100, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099ed184-8c18-44fc-bac1-64e93a408a53",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Other Data Structures</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             Veremos por aqui outros objetos de ordenação importantes para a biblioteca:\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb70e36-7228-43c4-b8a4-ffdb107c0d41",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> SparseTensor</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Equivalente a uma matriz esparsa do scipy. O módulo <em> tf.sparse</em> contém funções próprias para esse obejto.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06647cb0-f4b4-43e5-b0a0-889d0b592956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7facbdb04850>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando uma matriz identidade. Bastante apropriada para ser armazenada como um SparseTensor.\n",
    "sparse = tf.SparseTensor(indices=[[i,i] for i in range(5)], values=[1 for i in range(5)], dense_shape=[5,5])\n",
    "sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a440df2e-71d4-44ec-a2a7-1669de3f0440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=int32, numpy=\n",
       "array([[1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tornando o tensor denso.\n",
    "tf.sparse.to_dense(sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cb1e17-96eb-4e89-9b76-7543724f2a0f",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> TensorArray</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Listas de Tensores que podem ter um tamanho dinâmico.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62edc4a3-628a-4aa2-9aa1-6d63249744d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.tensor_array_ops.TensorArray at 0x7facbdb04df0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ta = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "ta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c59b9-e6f1-41e2-8ac9-e6e9dcdd6f49",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> RaggedTensor</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Listas de listas Tensores. Esses devem ter tamanho e data type únicos.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5469f389-3278-47c9-a03b-6a17489904a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'values' and 'row_partition'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_187225/3456916063.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mragged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRaggedTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'values' and 'row_partition'"
     ]
    }
   ],
   "source": [
    "ragged = tf.RaggedTensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a803289-de94-4bcb-94ba-07e30bfc5efb",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> String Tensors</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Tensores de strings. Por padrão, são por código byte, e não Unicode.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13ee46e1-cca2-4566-aef6-69e4dd44dafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=string, numpy=b'\\xc3\\xb4nibus'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veja como 'ô' é escrito.\n",
    "tf.Variable('ônibus')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629778cf-36d0-476c-b5b7-dca480080f13",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Sets</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            São tensores tratados como os objetos `set` do Python. O TF contém operações específicas a esses em `tf.sets`.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4bc98b-f9ac-444a-b723-f73fd3bf2436",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Queues</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Funcionam como os Queues built-in do Python, com o acréscimo de algumas classes apresentarem características particulares que podem ser úteis.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c27b08-994a-4bfb-a938-d9e6c28731f4",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Customizing Models and Training Algorithms</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Entendendo o básico sobre a manipulação de tensores, podemos começar a criar nossas próprias utilidades no TensorFlow.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94aabf9-2698-466f-8118-89c1049eadf1",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Custom Loss Functions</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O aconselhável é criarmos subclasses do objeto `keras.losses.Loss`. Isso facilitará o carregamento do modelo em usos posteriores.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5576f51e-a514-4619-a834-2babf50eff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma Huber Loss (ver capítulo 10). \n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        error = tf.abs(y_true - y_pred) # Erro absoluto.\n",
    "        is_small_error = error < self.threshold # Array booleano (o erro é maior do que o threshold).\n",
    "        \n",
    "        # Ambas as losses são computadas para uma mesma instância;\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = self.threshold * error - (self.threshold**2)/2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss) #error>thresold retorna loss linear; caso o contrário, ao quadrado.\n",
    "    \n",
    "    # `get_config` lida com o salvamento das configurações de argumentos para usos futuros da classe.\n",
    "    # Ou seja, caso eu defina `threshold`=2, esse valor será lembrado pelo algoritmo na próxima vez que eu for treiná-lo.\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'threshold':self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "929063b0-6ce1-46d6-a9e2-18920fdfbc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import boston_housing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# Carregando e tratando os dados.\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "norm = Normalizer()\n",
    "X_train_norm = norm.fit_transform(x_train)\n",
    "X_test_norm = norm.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecb2bd54-85df-497f-90a9-c55ad11cb29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montando uma rede neural rapidamente.\n",
    "from functools import partial\n",
    "DenseLayer = partial(keras.layers.Dense, activation='elu', use_bias=True, \n",
    "                     kernel_initializer=keras.initializers.LecunNormal(seed=42))\n",
    "\n",
    "# Função de montagem.\n",
    "def make_regnn(dense_layer:DenseLayer=DenseLayer, n_layers:int=4):\n",
    "    global X_train_norm\n",
    "    # Camada de input.\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Input(shape=X_train_norm.shape[1])\n",
    "                                    ])\n",
    "    # Hidden Layers.\n",
    "    for _ in range(n_layers):\n",
    "        model.add(DenseLayer(units=np.random.randint(low=20, high=40, size=1)))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        \n",
    "    # Camada de previsão.\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "# Criando o modelo.\n",
    "model = make_regnn()\n",
    "\n",
    "# Compilando o modelo.\n",
    "model.compile(optimizer=keras.optimizers.Nadam(learning_rate=10e-3), loss=HuberLoss(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d059c2b5-bf94-4df5-8cdc-6f950294e2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 42.7901 - val_loss: 43.4105\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 42.6556 - val_loss: 43.3766\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 42.5450 - val_loss: 43.2950\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 42.4295 - val_loss: 43.1455\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 42.3028 - val_loss: 43.0527\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 42.1617 - val_loss: 42.8725\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 42.0043 - val_loss: 42.5114\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 41.8292 - val_loss: 42.2148\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 41.6354 - val_loss: 41.9408\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 41.4219 - val_loss: 41.6937\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 41.1880 - val_loss: 41.3058\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 40.9329 - val_loss: 41.0409\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 40.6558 - val_loss: 40.8091\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 40.3563 - val_loss: 40.4808\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 40.0336 - val_loss: 40.0238\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 39.6873 - val_loss: 39.5159\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 39.3174 - val_loss: 39.9242\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 38.9219 - val_loss: 39.5861\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 38.5014 - val_loss: 39.2252\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 38.0553 - val_loss: 38.8428\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 37.5831 - val_loss: 38.4408\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 37.0845 - val_loss: 38.0110\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 36.5591 - val_loss: 37.5591\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 36.0066 - val_loss: 35.9970\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 35.4285 - val_loss: 30.0384\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 34.8196 - val_loss: 28.9553\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 34.1833 - val_loss: 27.8769\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 33.5185 - val_loss: 26.8101\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 32.8250 - val_loss: 25.7582\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 32.1025 - val_loss: 24.7163\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 31.3508 - val_loss: 23.6788\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 30.5696 - val_loss: 23.5732\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 29.7587 - val_loss: 22.6367\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 28.9179 - val_loss: 21.7039\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 28.0469 - val_loss: 20.7679\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 27.1456 - val_loss: 19.8444\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 26.2139 - val_loss: 18.9281\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 25.2516 - val_loss: 17.4143\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 24.2720 - val_loss: 16.1095\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 23.5432 - val_loss: 18.4450\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 22.3624 - val_loss: 15.3289\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 21.3135 - val_loss: 11.3618\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 20.1563 - val_loss: 11.3360\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 19.0420 - val_loss: 10.3916\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 17.9131 - val_loss: 11.4044\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.7810 - val_loss: 10.3293\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 15.5805 - val_loss: 10.2008\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 14.3728 - val_loss: 10.3319\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 13.1781 - val_loss: 10.7976\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 12.8116 - val_loss: 12.6996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7facb6a773d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finalmente, treinando a rede.\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "model.fit(X_train_norm, y_train, epochs=50, validation_data=(X_test_norm, y_test), steps_per_epoch=1, \n",
    "         callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6002567f-df6d-47ba-bc50-3d682883ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o modelo.\n",
    "model.save('models/hubber_nn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70a2d05d-f752-4b8a-81d0-f47fcc83b402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fac81bd8220>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ao carregar o modelo, precisaremos apenas mapear o nome do otimizador com sua respectiva classe.\n",
    "keras.models.load_model('models/hubber_nn.h5', \n",
    "                        custom_objects={'HuberLoss':HuberLoss})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15306cd-8cf0-4abd-bbc3-89c802e6848d",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Custom Activation Functions, Initializers, Regularizers and Constraints</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            A montagem desses outros objetos é praticamente a mesma. Crie uma classe herdeira de um objeto base e defina a operação dessa no método `call`.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a60874d1-3026-4545-87a7-478324c4b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Um regularizador L1.\n",
    "class L1Reg(keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    \n",
    "    # Norma L-1 dos coeficientes multiplicados por `self.factor`.\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    \n",
    "    # Método que garantirá que o `factor` definido pelo usuário seja lembrado para quando o modelo for carregado.\n",
    "    def get_config(self):\n",
    "        return {'factor':self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bf84c1f-4189-417b-8a74-3140ac4350da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 43.2144 - val_loss: 44.5734\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 43.0318 - val_loss: 44.3593\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 42.8420 - val_loss: 44.1298\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 42.6439 - val_loss: 43.8817\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 42.4372 - val_loss: 43.6187\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 42.2212 - val_loss: 43.3567\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 41.9957 - val_loss: 43.0787\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 41.7600 - val_loss: 42.8003\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 41.5139 - val_loss: 42.5299\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 41.2569 - val_loss: 42.2470\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 40.9885 - val_loss: 41.9539\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 40.7084 - val_loss: 41.6435\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 40.4160 - val_loss: 41.3262\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 40.1113 - val_loss: 40.9586\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 39.7945 - val_loss: 40.5914\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 39.4647 - val_loss: 40.2220\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 39.1212 - val_loss: 39.8435\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 38.7633 - val_loss: 39.4502\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 38.3907 - val_loss: 39.0418\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 38.0033 - val_loss: 38.6182\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 37.6007 - val_loss: 38.1789\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 37.1825 - val_loss: 37.7247\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 36.7482 - val_loss: 37.2511\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 36.2976 - val_loss: 36.7657\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 35.8304 - val_loss: 36.2621\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 35.3461 - val_loss: 35.7489\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 34.8445 - val_loss: 35.2150\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 34.3254 - val_loss: 34.6694\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 33.7885 - val_loss: 34.1142\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 33.2331 - val_loss: 33.5920\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 32.6597 - val_loss: 33.0495\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 32.0673 - val_loss: 32.4907\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 31.4556 - val_loss: 31.9108\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 30.9127 - val_loss: 31.1980\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 30.2212 - val_loss: 30.3109\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 29.5148 - val_loss: 29.4208\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 28.8336 - val_loss: 28.5583\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 28.1301 - val_loss: 27.7287\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 27.4007 - val_loss: 26.9060\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 26.6527 - val_loss: 26.0902\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 25.8840 - val_loss: 25.2743\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 25.0931 - val_loss: 24.4472\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 24.2814 - val_loss: 23.5912\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 23.4429 - val_loss: 22.7343\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 22.5847 - val_loss: 21.9031\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 21.7080 - val_loss: 21.0909\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 20.8063 - val_loss: 20.2977\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 19.8844 - val_loss: 19.4760\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 18.9429 - val_loss: 18.5734\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 17.9753 - val_loss: 17.7127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac80303fa0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Montando um outro modelo.\n",
    "DenseLayer = partial(keras.layers.Dense, activation='elu', use_bias=True, \n",
    "                     kernel_initializer=keras.initializers.LecunNormal(seed=42),\n",
    "                    kernel_regularizer=L1Reg(10e-4))\n",
    "\n",
    "model_l1 = make_regnn(DenseLayer, n_layers=5)\n",
    "\n",
    "model_l1.compile(optimizer=keras.optimizers.Adam(learning_rate=10e-3), loss=HuberLoss(2))\n",
    "\n",
    "model_l1.fit(X_train_norm, y_train, epochs=50, validation_data=(X_test_norm, y_test), steps_per_epoch=1, \n",
    "         callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1a4d2a-294b-4acf-859f-a2e12551144e",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px;color:red'> Um Fato Relevante</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Ao montar essa última NN, comecei com $\\eta=10^{-2}$; a 'val_loss' ficou instável. Depois, parti para $\\eta=10^{-4}$; a loss se estabilizou em um valor alto. Por último, tentei $\\eta=10^{-3}$; finalmente, houve conversão!\n",
    "        </li>\n",
    "        <li> \n",
    "            Por isso, na ausência de uma descida efetiva de gradiente, experimente outras learning rates antes de duvidar do tratamento dos dados!\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97288655-debf-405f-8b9d-781dc6a5e534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fac80569fd0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agora, salvando carregando o algoritmo.\n",
    "model_l1.save('models/l1_nn.h5')\n",
    "\n",
    "# `custom_objects` deverá receber dois itens com a criação de `L1Reg`.   \n",
    "keras.models.load_model('models/l1_nn.h5', custom_objects={'HuberLoss':HuberLoss, 'L1Reg':L1Reg})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc78ed0-3f72-42f4-ace4-dcb7ce11498d",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Custom Metrics</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30caefbc-3ab7-4047-96c0-006591d84999",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Custom Layers</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            É possível montar um tipo de camada exótico para a rede neural. Para isso, não há nenhuma novidade: apenas crie uma classe herdeira. \n",
    "        </li>\n",
    "        <li> \n",
    "            Mas, ainda mais interessante, é que conseguimos gerar uma camada-envelope contendo várias camadas. Isso é útil quando utilizamos as classes `BatchNormalization` e `Dropout` juntamente com a `Dense`.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d9f7e0b2-644a-4781-ae7e-47929dfdf866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.lambda_layer.Lambda at 0x7fac53caebb0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Um outro fato: caso queira usar uma função de ativação customizável, use a classe `Lambda`, do keras.layers.\n",
    "\n",
    "# Usando a derivada da tangente inversa.\n",
    "keras.layers.Lambda(lambda x: 1/(1+tf.square(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e01cdd17-a516-46d5-b2af-e378ef4d0ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uma Dense Layer customizável.\n",
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units:int, activation:str, **kwargs):\n",
    "        # Configurações do usuário.\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        \n",
    "    def build(self, batch_input_shape):\n",
    "        # A camada possuirá tanto um kernel, quanto um vetor de bias.\n",
    "        self.kernel = self.add_weight(name='kernel', shape=(batch_input_shape[-1], self.units), initializer='he_normal')\n",
    "        self.bias = self.add_weight(name='bias', shape=[self.units], initializer='ones')\n",
    "        super().build(batch_input_shape) # Usando `super` para invocar o método build da classe-parente (`Layer`).\n",
    "    \n",
    "    # `call` apenas efetua a conta que desejamos fazer: multiplicar as features pelos weights e somar o produto com o vetor de bias.\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "    \n",
    "    # Função que computa o shape da camada.\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "    \n",
    "    # Mesma funcionalidade que nos últimos casos.\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        # `serialize` é o inverso do método `get`. Ou seja, retorna a string identificadora da função, dado o seu objeto.\n",
    "        return {**base_config, 'units':self.units, 'activation':keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "244a35c9-8238-4a2d-8a59-f9207985fccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizers.optimizer_v2.nadam.Nadam at 0x7fac51db3eb0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podemos também desejar montar uma camada de múltiplos inputs e outputs.\n",
    "class MultiLayer(keras.layers.Layer):\n",
    "    # Nossa `MultiLayer` admitirá uma tupla com dois inputs.\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        # A camada retornará 3 outputs.\n",
    "        return [X1+X2, X1*X2, tf.square(X1+X2)/2]\n",
    "    \n",
    "    # Método que retorna o shape de cada output\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        b1, b2 = batch_input_shape\n",
    "        return [b1, b1, b1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d70305e-2ba8-49f9-8b24-58b051a7265d",
   "metadata": {},
   "source": [
    "<p style='color:red'> Grifado p.517</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
