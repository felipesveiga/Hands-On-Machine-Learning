{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9bd146-d458-49fe-a33e-c432ddd18ec3",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'> Custom Models and Training with TensorFlow</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e16877-5c58-47cd-b034-c461ae8b360c",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Exploraremos as outras funcionalidades contidas no TensorFlow. Seu ecossistema possui módulos para tratar os mais diversos problemas do Machine Learning. Segue o diagrama apresentado pelo livro:\n",
    "            <center style='margin-top:10px'> \n",
    "                <img src='tf_diag.png'>\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d521d7e-aee9-44f6-abc7-85c53cd49893",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Using TensorFlow Like Numpy</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O TensorFlow contém funcionalidades muito próximas das do numpy. No caso, somos capazes de criar tensores (espécies de matrizes) e executar certas operações matemáticas.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39abffd3-189c-4465-982c-8a50bf8ae170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-21 13:23:06.964082: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /u01/app/oracle/product/11.2.0/xe/lib:/lib:/usr/local/lib:\n",
      "2023-01-21 13:23:06.964116: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-21 13:23:10.910066: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /u01/app/oracle/product/11.2.0/xe/lib:/lib:/usr/local/lib:\n",
      "2023-01-21 13:23:10.910093: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-21 13:23:10.910119: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (veiga-Inspiron): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5]], dtype=int32)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando um tensor com `tf.constant`.\n",
    "\n",
    "# A particularidade desse objeto é a sua imutabilidade (não pode ser alterado in-place).\n",
    "import tensorflow as tf\n",
    "tf.constant(range(6), shape=(3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0f36d44-0488-4857-baeb-28b1d31bc91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=23>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Os tensores admitem receberem números soltos também.\n",
    "tf.constant(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c038638a-f613-4c53-a37d-e4e95ec1a006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.sqrt: [[0.    1.    1.414]\n",
      " [1.732 2.    2.236]\n",
      " [2.45  2.646 2.828]\n",
      " [3.    3.162 3.316]]\n",
      "\n",
      "L2: [11.23  12.88  14.625]\n"
     ]
    }
   ],
   "source": [
    "# A maior parte das funções do Numpy também são encontradas no TF. Essas podem ter nomes um pouco distintos, ou ainda estarem\n",
    "# dentro do módulo `tensorflow.math`.\n",
    "t = tf.constant(range(12), dtype=tf.float16, shape=(4,3))\n",
    "print(f'tf.sqrt: {tf.sqrt(t)}', end='\\n\\n')\n",
    "\n",
    "# A norma l-2 é encontrada no em `math`.\n",
    "from tensorflow.math import reduce_euclidean_norm\n",
    "print(f'L2: {reduce_euclidean_norm(t, axis=0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb75fbf6-0f90-4dbf-be39-a6299d321392",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Keras' Low-Level API</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             O Keras também contém certas funcionalidades voltadas à manipulação de matrizes em <em> keras.backend</em>. É útil usá-lo quando queremos que haja portabilidade de nosso código com outras implementações Keras.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fef9698e-b7e0-4775-843b-89fa6875c9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float16, numpy=\n",
       "array([[  0.,   1.,   4.],\n",
       "       [  9.,  16.,  25.],\n",
       "       [ 36.,  49.,  64.],\n",
       "       [ 81., 100., 121.]], dtype=float16)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# É costumaz se referir ao módulo como 'K'.\n",
    "import tensorflow.keras.backend as K\n",
    "K.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571860d8-9fa3-4caa-ba60-e700a4485828",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Tensors and NumPy</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Tensores TF podem se originar a partir de arrays do numpy e vice-versa.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3206b0da-f385-4302-8f3e-5308ff4f5de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conseguimos, inclusive, aplicar funções do numpy diretamente em tensores!\n",
    "import numpy as np\n",
    "np.linalg.norm(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0ad002f-416a-4891-bc09-c5a6247a60d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando um tensor com um array.\n",
    "a = np.arange(10)\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b784a-f672-4ff3-9eb0-a14c2d14d66d",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Type Conversions</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Diferentemente do numpy, o TensorFlow não faz adaptações de data types em seus procedimentos. Isso significa que manipular um array de integer com um de float, por exemplo, resultará em erro.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6adabd58-12e6-4567-827a-3862e641283b",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute AddV2 as input #1(zero-based) was expected to be a half tensor but is a float tensor [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_187225/1444564877.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 'float16'+ 'float32'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7162\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7163\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7164\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute AddV2 as input #1(zero-based) was expected to be a half tensor but is a float tensor [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "t2 = tf.constant(range(10, 22), shape=(4,3), dtype=tf.float32)\n",
    "\n",
    "# 'float16'+ 'float32'.\n",
    "t+t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdc3d806-702f-4185-aaa8-05ec969ac7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float16, numpy=\n",
       "array([[10., 12., 14.],\n",
       "       [16., 18., 20.],\n",
       "       [22., 24., 26.],\n",
       "       [28., 30., 32.]], dtype=float16)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use `cast` para alterar o data type do tensor.\n",
    "t + tf.cast(t2, tf.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31df0fd-d9a4-4f19-83e5-945ab2221c5e",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Variables</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            <em>tf.variable</em> é também um tensor, mas que admite alterações in-place.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cc864dd-768f-4dff-8f6b-6732255fb2df",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(4, 4) dtype=float32, numpy=\n",
       "array([[ 1.,  2.,  3.,  4.],\n",
       "       [ 2.,  4.,  6.,  8.],\n",
       "       [ 3.,  6.,  9., 12.],\n",
       "       [ 4.,  8., 12., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando uma variável.\n",
    "v = tf.Variable([[i*a for i in range(1,5)] for a in range(1,5)], dtype=tf.float32)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "949998b6-1138-42a1-ac5b-268d6da170d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(4, 4) dtype=float32, numpy=\n",
       "array([[ 1., 20.,  3.,  4.],\n",
       "       [ 2.,  4.,  6.,  8.],\n",
       "       [ 3.,  6.,  9., 12.],\n",
       "       [ 4.,  8., 12., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usando `assign` para modificar a posição [0,1].\n",
    "v[0,1].assign(20)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c42758e4-956c-48dc-89cf-8d6ffd7323e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(4, 4) dtype=float32, numpy=\n",
       "array([[  1.,  20.,   3.,   4.],\n",
       "       [  2., 100.,   6.,   8.],\n",
       "       [  3.,   6.,   9.,  12.],\n",
       "       [  4.,   8., 200.,  16.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `scatter_nd_update` modifica múltiplos elementos de uma só vez.\n",
    "v.scatter_nd_update(indices=[[1,1], [3,2]], updates=[100, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099ed184-8c18-44fc-bac1-64e93a408a53",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Other Data Structures</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             Veremos por aqui outros objetos de ordenação importantes para a biblioteca:\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb70e36-7228-43c4-b8a4-ffdb107c0d41",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> SparseTensor</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Equivalente a uma matriz esparsa do scipy. O módulo <em> tf.sparse</em> contém funções próprias para esse obejto.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06647cb0-f4b4-43e5-b0a0-889d0b592956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7facbdb04850>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando uma matriz identidade. Bastante apropriada para ser armazenada como um SparseTensor.\n",
    "sparse = tf.SparseTensor(indices=[[i,i] for i in range(5)], values=[1 for i in range(5)], dense_shape=[5,5])\n",
    "sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a440df2e-71d4-44ec-a2a7-1669de3f0440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=int32, numpy=\n",
       "array([[1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tornando o tensor denso.\n",
    "tf.sparse.to_dense(sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cb1e17-96eb-4e89-9b76-7543724f2a0f",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> TensorArray</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Listas de Tensores que podem ter um tamanho dinâmico.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62edc4a3-628a-4aa2-9aa1-6d63249744d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.tensor_array_ops.TensorArray at 0x7facbdb04df0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ta = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "ta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c59b9-e6f1-41e2-8ac9-e6e9dcdd6f49",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> RaggedTensor</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Listas de listas Tensores. Esses devem ter tamanho e data type únicos.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5469f389-3278-47c9-a03b-6a17489904a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'values' and 'row_partition'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_187225/3456916063.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mragged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRaggedTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'values' and 'row_partition'"
     ]
    }
   ],
   "source": [
    "ragged = tf.RaggedTensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a803289-de94-4bcb-94ba-07e30bfc5efb",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> String Tensors</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Tensores de strings. Por padrão, são por código byte, e não Unicode.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13ee46e1-cca2-4566-aef6-69e4dd44dafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=string, numpy=b'\\xc3\\xb4nibus'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veja como 'ô' é escrito.\n",
    "tf.Variable('ônibus')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629778cf-36d0-476c-b5b7-dca480080f13",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Sets</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            São tensores tratados como os objetos `set` do Python. O TF contém operações específicas a esses em `tf.sets`.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4bc98b-f9ac-444a-b723-f73fd3bf2436",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Queues</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Funcionam como os Queues built-in do Python, com o acréscimo de algumas classes apresentarem características particulares que podem ser úteis.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c27b08-994a-4bfb-a938-d9e6c28731f4",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Customizing Models and Training Algorithms</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Entendendo o básico sobre a manipulação de tensores, podemos começar a criar nossas próprias utilidades no TensorFlow.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94aabf9-2698-466f-8118-89c1049eadf1",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Custom Loss Functions</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O aconselhável é criarmos subclasses do objeto `keras.losses.Loss`. Isso facilitará o carregamento do modelo em usos posteriores.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5576f51e-a514-4619-a834-2babf50eff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma Huber Loss (ver capítulo 10). \n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        error = tf.abs(y_true - y_pred) # Erro absoluto.\n",
    "        is_small_error = error < self.threshold # Array booleano (o erro é maior do que o threshold).\n",
    "        \n",
    "        # Ambas as losses são computadas para uma mesma instância;\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = self.threshold * error - (self.threshold**2)/2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss) #error>thresold retorna loss linear; caso o contrário, ao quadrado.\n",
    "    \n",
    "    # `get_config` lida com o salvamento das configurações de argumentos para usos futuros da classe.\n",
    "    # Ou seja, caso eu defina `threshold`=2, esse valor será lembrado pelo algoritmo na próxima vez que eu for treiná-lo.\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'threshold':self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "929063b0-6ce1-46d6-a9e2-18920fdfbc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import boston_housing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# Carregando e tratando os dados.\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "norm = Normalizer()\n",
    "X_train_norm = norm.fit_transform(x_train)\n",
    "X_test_norm = norm.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecb2bd54-85df-497f-90a9-c55ad11cb29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montando uma rede neural rapidamente.\n",
    "from functools import partial\n",
    "DenseLayer = partial(keras.layers.Dense, activation='elu', use_bias=True, \n",
    "                     kernel_initializer=keras.initializers.LecunNormal(seed=42))\n",
    "\n",
    "# Função de montagem.\n",
    "def make_regnn(dense_layer:DenseLayer=DenseLayer, n_layers:int=4):\n",
    "    global X_train_norm\n",
    "    # Camada de input.\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Input(shape=X_train_norm.shape[1])\n",
    "                                    ])\n",
    "    # Hidden Layers.\n",
    "    for _ in range(n_layers):\n",
    "        model.add(DenseLayer(units=np.random.randint(low=20, high=40, size=1)))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        \n",
    "    # Camada de previsão.\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "# Criando o modelo.\n",
    "model = make_regnn()\n",
    "\n",
    "# Compilando o modelo.\n",
    "model.compile(optimizer=keras.optimizers.Nadam(learning_rate=10e-3), loss=HuberLoss(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d059c2b5-bf94-4df5-8cdc-6f950294e2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 42.7901 - val_loss: 43.4105\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 42.6556 - val_loss: 43.3766\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 42.5450 - val_loss: 43.2950\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 42.4295 - val_loss: 43.1455\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 42.3028 - val_loss: 43.0527\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 42.1617 - val_loss: 42.8725\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 42.0043 - val_loss: 42.5114\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 41.8292 - val_loss: 42.2148\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 41.6354 - val_loss: 41.9408\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 41.4219 - val_loss: 41.6937\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 41.1880 - val_loss: 41.3058\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 40.9329 - val_loss: 41.0409\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 40.6558 - val_loss: 40.8091\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 40.3563 - val_loss: 40.4808\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 40.0336 - val_loss: 40.0238\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 39.6873 - val_loss: 39.5159\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 39.3174 - val_loss: 39.9242\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 38.9219 - val_loss: 39.5861\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 38.5014 - val_loss: 39.2252\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 38.0553 - val_loss: 38.8428\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 37.5831 - val_loss: 38.4408\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 37.0845 - val_loss: 38.0110\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 36.5591 - val_loss: 37.5591\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 36.0066 - val_loss: 35.9970\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 35.4285 - val_loss: 30.0384\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 34.8196 - val_loss: 28.9553\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 34.1833 - val_loss: 27.8769\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 33.5185 - val_loss: 26.8101\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 32.8250 - val_loss: 25.7582\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 32.1025 - val_loss: 24.7163\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 31.3508 - val_loss: 23.6788\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 30.5696 - val_loss: 23.5732\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 29.7587 - val_loss: 22.6367\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 28.9179 - val_loss: 21.7039\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 28.0469 - val_loss: 20.7679\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 27.1456 - val_loss: 19.8444\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 26.2139 - val_loss: 18.9281\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 25.2516 - val_loss: 17.4143\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 24.2720 - val_loss: 16.1095\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 23.5432 - val_loss: 18.4450\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 22.3624 - val_loss: 15.3289\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 21.3135 - val_loss: 11.3618\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 20.1563 - val_loss: 11.3360\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 19.0420 - val_loss: 10.3916\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 17.9131 - val_loss: 11.4044\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 16.7810 - val_loss: 10.3293\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 15.5805 - val_loss: 10.2008\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 14.3728 - val_loss: 10.3319\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 13.1781 - val_loss: 10.7976\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 12.8116 - val_loss: 12.6996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7facb6a773d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finalmente, treinando a rede.\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "model.fit(X_train_norm, y_train, epochs=50, validation_data=(X_test_norm, y_test), steps_per_epoch=1, \n",
    "         callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6002567f-df6d-47ba-bc50-3d682883ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o modelo.\n",
    "model.save('models/hubber_nn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70a2d05d-f752-4b8a-81d0-f47fcc83b402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fac81bd8220>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ao carregar o modelo, precisaremos apenas mapear o nome do otimizador com sua respectiva classe.\n",
    "keras.models.load_model('models/hubber_nn.h5', \n",
    "                        custom_objects={'HuberLoss':HuberLoss})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15306cd-8cf0-4abd-bbc3-89c802e6848d",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Custom Activation Functions, Initializers, Regularizers and Constraints</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            A montagem desses outros objetos é praticamente a mesma. Crie uma classe herdeira de um objeto base e defina a operação dessa no método `call`.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a60874d1-3026-4545-87a7-478324c4b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Um regularizador L1.\n",
    "class L1Reg(keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    \n",
    "    # Norma L-1 dos coeficientes multiplicados por `self.factor`.\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    \n",
    "    # Método que garantirá que o `factor` definido pelo usuário seja lembrado para quando o modelo for carregado.\n",
    "    def get_config(self):\n",
    "        return {'factor':self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bf84c1f-4189-417b-8a74-3140ac4350da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 43.2144 - val_loss: 44.5734\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 43.0318 - val_loss: 44.3593\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 42.8420 - val_loss: 44.1298\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 42.6439 - val_loss: 43.8817\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 42.4372 - val_loss: 43.6187\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 42.2212 - val_loss: 43.3567\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 41.9957 - val_loss: 43.0787\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 41.7600 - val_loss: 42.8003\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 41.5139 - val_loss: 42.5299\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 41.2569 - val_loss: 42.2470\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 40.9885 - val_loss: 41.9539\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 40.7084 - val_loss: 41.6435\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 40.4160 - val_loss: 41.3262\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 40.1113 - val_loss: 40.9586\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 39.7945 - val_loss: 40.5914\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 39.4647 - val_loss: 40.2220\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 39.1212 - val_loss: 39.8435\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 38.7633 - val_loss: 39.4502\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 38.3907 - val_loss: 39.0418\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 38.0033 - val_loss: 38.6182\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 37.6007 - val_loss: 38.1789\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 37.1825 - val_loss: 37.7247\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 36.7482 - val_loss: 37.2511\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 36.2976 - val_loss: 36.7657\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 35.8304 - val_loss: 36.2621\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 35.3461 - val_loss: 35.7489\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 34.8445 - val_loss: 35.2150\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 34.3254 - val_loss: 34.6694\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 33.7885 - val_loss: 34.1142\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 33.2331 - val_loss: 33.5920\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 32.6597 - val_loss: 33.0495\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 32.0673 - val_loss: 32.4907\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 31.4556 - val_loss: 31.9108\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 30.9127 - val_loss: 31.1980\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 30.2212 - val_loss: 30.3109\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 29.5148 - val_loss: 29.4208\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 28.8336 - val_loss: 28.5583\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 28.1301 - val_loss: 27.7287\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 27.4007 - val_loss: 26.9060\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 26.6527 - val_loss: 26.0902\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 25.8840 - val_loss: 25.2743\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 25.0931 - val_loss: 24.4472\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 24.2814 - val_loss: 23.5912\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 23.4429 - val_loss: 22.7343\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 22.5847 - val_loss: 21.9031\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 21.7080 - val_loss: 21.0909\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 20.8063 - val_loss: 20.2977\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 19.8844 - val_loss: 19.4760\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 18.9429 - val_loss: 18.5734\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 17.9753 - val_loss: 17.7127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac80303fa0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Montando um outro modelo.\n",
    "DenseLayer = partial(keras.layers.Dense, activation='elu', use_bias=True, \n",
    "                     kernel_initializer=keras.initializers.LecunNormal(seed=42),\n",
    "                    kernel_regularizer=L1Reg(10e-4))\n",
    "\n",
    "model_l1 = make_regnn(DenseLayer, n_layers=5)\n",
    "\n",
    "model_l1.compile(optimizer=keras.optimizers.Adam(learning_rate=10e-3), loss=HuberLoss(2))\n",
    "\n",
    "model_l1.fit(X_train_norm, y_train, epochs=50, validation_data=(X_test_norm, y_test), steps_per_epoch=1, \n",
    "         callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1a4d2a-294b-4acf-859f-a2e12551144e",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px;color:red'> Um Fato Relevante</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Ao montar essa última NN, comecei com $\\eta=10^{-2}$; a 'val_loss' ficou instável. Depois, parti para $\\eta=10^{-4}$; a loss se estabilizou em um valor alto. Por último, tentei $\\eta=10^{-3}$; finalmente, houve conversão!\n",
    "        </li>\n",
    "        <li> \n",
    "            Por isso, na ausência de uma descida efetiva de gradiente, experimente outras learning rates antes de duvidar do tratamento dos dados!\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97288655-debf-405f-8b9d-781dc6a5e534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fac80569fd0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agora, salvando carregando o algoritmo.\n",
    "model_l1.save('models/l1_nn.h5')\n",
    "\n",
    "# `custom_objects` deverá receber dois itens com a criação de `L1Reg`.   \n",
    "keras.models.load_model('models/l1_nn.h5', custom_objects={'HuberLoss':HuberLoss, 'L1Reg':L1Reg})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc78ed0-3f72-42f4-ace4-dcb7ce11498d",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Custom Metrics</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30caefbc-3ab7-4047-96c0-006591d84999",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Custom Layers</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            É possível montar um tipo de camada exótico para a rede neural. Para isso, não há nenhuma novidade: apenas crie uma classe herdeira. \n",
    "        </li>\n",
    "        <li> \n",
    "            Mas, ainda mais interessante, é que conseguimos gerar uma camada-envelope contendo várias camadas. Isso é útil quando utilizamos as classes `BatchNormalization` e `Dropout` juntamente com a `Dense`.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d9f7e0b2-644a-4781-ae7e-47929dfdf866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.lambda_layer.Lambda at 0x7fac53caebb0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Um outro fato: caso queira usar uma função de ativação customizável, use a classe `Lambda`, do keras.layers.\n",
    "\n",
    "# Usando a derivada da tangente inversa.\n",
    "keras.layers.Lambda(lambda x: 1/(1+tf.square(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e01cdd17-a516-46d5-b2af-e378ef4d0ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uma Dense Layer customizável.\n",
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units:int, activation:str, **kwargs):\n",
    "        # Configurações do usuário.\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        \n",
    "    def build(self, batch_input_shape):\n",
    "        # A camada possuirá tanto um kernel, quanto um vetor de bias.\n",
    "        self.kernel = self.add_weight(name='kernel', shape=(batch_input_shape[-1], self.units), initializer='he_normal')\n",
    "        self.bias = self.add_weight(name='bias', shape=[self.units], initializer='ones')\n",
    "        super().build(batch_input_shape) # Usando `super` para invocar o método build da classe-parente (`Layer`).\n",
    "    \n",
    "    # `call` apenas efetua a conta que desejamos fazer: multiplicar as features pelos weights e somar o produto com o vetor de bias.\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "    \n",
    "    # Função que computa o shape da camada.\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "    \n",
    "    # Mesma funcionalidade que nos últimos casos.\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        # `serialize` é o inverso do método `get`. Ou seja, retorna a string identificadora da função, dado o seu objeto.\n",
    "        return {**base_config, 'units':self.units, 'activation':keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "244a35c9-8238-4a2d-8a59-f9207985fccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos também montar uma camada de múltiplos inputs e outputs.\n",
    "class MultiLayer(keras.layers.Layer):\n",
    "    # Nossa `MultiLayer` admitirá uma tupla com dois inputs.\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        # A camada retornará 3 outputs.\n",
    "        return [X1+X2, X1*X2, tf.square(X1+X2)/2]\n",
    "    \n",
    "    # Método que retorna o shape de cada output\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        b1, b2 = batch_input_shape\n",
    "        return [b1, b1, b1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b351867b-b9b0-4ba8-85c6-aaac1d115a04",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Como vimos com Dropout, uma camada pode demonstrar comportamentos distintos a depender se estamos em fase de treino ou teste. Se quisermos que nossa camada apresente tais nuances, crie um argumento 'training' em `call`.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fe2c3a40-e024-471c-b223-7b003cffc352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe para adição de noise Gaussiano.\n",
    "class MyGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev # Desvio-Padrão da Distribuição Normal.\n",
    "        \n",
    "    def call(self, X, training=False):\n",
    "        # Se 'training' for True, retornar X acrescido de 'noise'.\n",
    "        if training:\n",
    "            noise = tf.random.normal(shape=tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "    def compute_output_shape(batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "31646be8-8c6a-40cf-88e5-780da82ddcda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MyWrapper at 0x7fac49ec9f40>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Por último, uma camada-envelope com uma Dense, Batch e Dropout.\n",
    "from typing import List\n",
    "class MyWrapper(keras.layers.Layer):\n",
    "    def __init__(self, dense_units:int, trainable:bool=True,**kwargs):\n",
    "        super().__init__()\n",
    "        self.dense_units= dense_units\n",
    "        self.trainable = trainable\n",
    "        self.hidden = [keras.layers.Dense(units=self.dense_units, **kwargs),\n",
    "                       keras.layers.Dropout(.5, trainable=self.trainable),\n",
    "                      keras.layers.BatchNormalization()]\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return Z\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'units':self.dense_units, 'trainable':self.trainable}\n",
    "        \n",
    "        \n",
    "MyWrapper(50, activation='elu', kernel_initializer='lecun_normal', use_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "44ded23a-ad91-4792-b1f7-f8f7247da969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialização com input layer.\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_norm.shape[1])\n",
    "])\n",
    "\n",
    "# Hidden Layers.\n",
    "for _ in range(4):\n",
    "    model.add(MyWrapper(50, activation = 'elu', bias_initializer='ones', kernel_initializer='lecun_normal', use_bias=True))\n",
    "       \n",
    "# Camada de Output.\n",
    "model.add(keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "68ef12a3-48fb-486b-9901-541535c93556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 577.2795 - val_loss: 566.7376\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 573.3362 - val_loss: 531.5291\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 570.5959 - val_loss: 543.2615\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 566.0503 - val_loss: 528.8618\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 559.7664 - val_loss: 536.2296\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 556.6844 - val_loss: 549.4236\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 552.5057 - val_loss: 549.6432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac4db79670>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compilação do modelo.\n",
    "model.compile(optimizer=keras.optimizers.Nadam(learning_rate=10e-3), loss=keras.losses.MeanSquaredError())\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "model.fit(X_train_norm, y_train, epochs=50, validation_data=(X_test_norm, y_test), steps_per_epoch=1, \n",
    "         callbacks=[early_stopping], use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc36889-3cc0-4107-a951-ffe1a70f0b2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Custom Models</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Se precisarmos, podemos criar modelo personalizados facilmente.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "9f09e53b-7f97-4cea-b7e7-8e782128f41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O último modelo poderia ser facilmente montado como um objeto.\n",
    "class MySequential(keras.Model): \n",
    "    \n",
    "    # Montagem da estrutura.\n",
    "    @staticmethod\n",
    "    def add_layers():\n",
    "        layout = [keras.layers.Input(shape=X_train_norm.shape[1])]\n",
    "        for _ in range(4):\n",
    "            layout.append(MyWrapper(50, activation = 'elu', bias_initializer='ones', kernel_initializer='lecun_normal', use_bias=True))\n",
    "        # Camada de output.\n",
    "        layout.append(keras.layers.Dense(1))\n",
    "        return layout\n",
    "        \n",
    "    \n",
    "    def __init__(self, n_layers,**kwargs):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.layout = MySequential.add_layers()\n",
    "    \n",
    "    # `call` é chamado na realização das previsões.\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.layers:\n",
    "            Z = layer(Z)\n",
    "        return Z\n",
    "my_sequential = MySequential(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "bfb7fa93-bdfd-4d0c-b0c0-f21d161edd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 3s 25ms/step - loss: 575.9229 - val_loss: 562.0528\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 569.2520 - val_loss: 561.9946\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 563.7677 - val_loss: 561.0911\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 558.9291 - val_loss: 554.6983\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 550.4096 - val_loss: 551.1938\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 542.1558 - val_loss: 541.2669\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 528.4458 - val_loss: 531.4620\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 518.9763 - val_loss: 520.6923\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 507.6285 - val_loss: 509.8851\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 496.4070 - val_loss: 494.4759\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 480.7421 - val_loss: 482.0732\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 467.0816 - val_loss: 464.9489\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 452.6119 - val_loss: 449.4620\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 431.3941 - val_loss: 431.8872\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 409.9439 - val_loss: 415.1803\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 387.4319 - val_loss: 393.2283\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 379.1642 - val_loss: 369.3197\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 350.0427 - val_loss: 350.2329\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 331.4207 - val_loss: 337.2948\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 314.3202 - val_loss: 319.7862\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 294.3118 - val_loss: 302.5898\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 277.5979 - val_loss: 288.0251\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 259.4146 - val_loss: 269.6302\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 241.2452 - val_loss: 255.2761\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 227.0016 - val_loss: 232.8756\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 214.3124 - val_loss: 215.5709\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 192.5067 - val_loss: 197.9397\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 179.1545 - val_loss: 185.4901\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 174.1627 - val_loss: 166.9919\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 158.8058 - val_loss: 152.8414\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 142.7056 - val_loss: 139.4874\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 137.6732 - val_loss: 129.8045\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 129.1858 - val_loss: 118.4892\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 122.6436 - val_loss: 109.1527\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 117.2254 - val_loss: 99.8556\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 107.7405 - val_loss: 93.6014\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 103.4633 - val_loss: 88.9535\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 94.9158 - val_loss: 83.2409\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 95.3471 - val_loss: 77.1905\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 87.1345 - val_loss: 72.8210\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 88.1595 - val_loss: 69.6646\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 86.7432 - val_loss: 68.6678\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 89.9779 - val_loss: 67.4219\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 77.0376 - val_loss: 65.9991\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 78.1087 - val_loss: 65.3439\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 73.3517 - val_loss: 65.4788\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 74.8497 - val_loss: 63.2034\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 78.7870 - val_loss: 62.1243\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 75.8494 - val_loss: 61.0651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac4d7082b0>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compilando e treinando o nosso próprio modelo!\n",
    "my_sequential.compile(optimizer='nadam', loss='mse')\n",
    "my_sequential.fit(X_train_norm, y_train, epochs=100, callbacks=[early_stopping], validation_data=(X_test_norm, y_test),\n",
    "               workers=-1, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "535222f1-6a84-4fc6-a04b-084cf3c38080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_159_layer_call_fn, dense_159_layer_call_and_return_conditional_losses, dropout_66_layer_call_fn, dropout_66_layer_call_and_return_conditional_losses, dense_160_layer_call_fn while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/my_sequential.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/my_sequential.tf/assets\n"
     ]
    }
   ],
   "source": [
    "# Salvando modelo e weights.\n",
    "keras.models.save_model(my_sequential, 'models/my_sequential.tf')\n",
    "\n",
    "#! mkdir weights\n",
    "my_sequential.save_weights('weights/my_sequential_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "42ceaa1f-6ac2-4166-883d-cfdec8d7e2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora, simulando o carregamento do modelo com seus weights.\n",
    "my_loaded_sequential = keras.models.load_model('models/my_sequential.tf')\n",
    "\n",
    "# Fiz um teste e, aparentemente, o `load_model` deu conta de carregar os coeficientes automaticamente.\n",
    "# De qualquer maneira, usar o `load_weights` não afeta absolutamente nada.\n",
    "my_loaded_sequential.load_weights('weights/my_sequential_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "cb390cea-3db9-4b7a-9f63-de7d4610f239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 65.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65.9991455078125"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaliando o modelo.\n",
    "my_loaded_sequential.evaluate(X_test_norm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf6ea9-49d3-486e-9501-7e63603867f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Losses and Metrics Based on Model Internals</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Esta seção apresenta como fazemos para acrescentar novas losses ao modelo, é só passar self.add_loss em `call`. Não vou reproduzir toda a classe criada no livro. \n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eab34c-f49a-4bf1-9dd4-77fda07d74c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Computing Gradients with Autodiff</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Como vimos em otimizadores, a computação dos gradientes é a tarefa essencial do treinamento. O TensorFlow providencia o objeto GradientTape, que é capaz de calcular as parciais de uma função.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "e69cc722-0382-461a-b600-4f97e5ee3911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando uma função a sofrer diferenciação.\n",
    "def f(w1, w2):\n",
    "    return 3*w1**2  + 2*w1*w2\n",
    "\n",
    "# Declarando as coordenadas de onde o gradiente será mensurado. Os números devem ser float!\n",
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "    \n",
    "tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "466c714e-5ec2-4998-95da-22c655b67fc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_187225/417907156.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# O uso das funções da classe ocorre apenas uma vez, por padrão.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \"\"\"\n\u001b[1;32m   1039\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m       raise RuntimeError(\"A non-persistent GradientTape can only be used to \"\n\u001b[0m\u001b[1;32m   1041\u001b[0m                          \"compute one set of gradients (or jacobians)\")\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recording\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)"
     ]
    }
   ],
   "source": [
    "# O uso das funções da classe ocorre apenas uma vez, por padrão.\n",
    "tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "e63ac7fe-8afc-49c9-8605-929a6d0e0eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso queira utilizar o objeto várias vezes, defina `persistent`=True\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "    \n",
    "tape.gradient(z, [w1, w2])\n",
    "\n",
    "# Usando `tape` uma segunda vez para obter a parcial de `w1`.\n",
    "tape.gradient(z, w1)\n",
    "\n",
    "# Para desativar a classe, use 'del'.\n",
    "del tape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563ce25e-e0d8-4e58-bbeb-1aea8860097c",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O objeto `GradientTape` está configurado para apenas lidar com `tf.Variable`. Mas, se desejar usar outros objetos, use o método  'watch'.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "a8f4f49c-fe77-47aa-9fde-e04df879b6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trocando Variables por constantes.\n",
    "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    # Solicitando `tape` para monitorar as constantes.\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z = f(c1, c2)\n",
    "    \n",
    "tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb62811-b55b-4b38-9ec4-4230989055ce",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "                 O `tf.GradientTape` ainda pode cair em indeterminações. Um caso disso seria com a função softplus. A classe provavelmente considera a sua derivada como $\\frac{e^{x}}{e^{x}+1}$, caindo na indeterminação $\\frac{\\infty}{\\infty}$ quando $x \\to \\infty$.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "59e39fa3-598b-4013-9b73-effc544d98c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=nan>]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softplus(w1):\n",
    "    return tf.math.log(tf.exp(w1) + 1)\n",
    "\n",
    "# Pondo um argumento bastante alto.\n",
    "w1 = tf.Variable(10e10)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = softplus(w1)\n",
    "\n",
    "# Veja, a classe retorna um NaN.\n",
    "tape.gradient(z, [w1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "5b938204-6789-4be2-a5d6-b6dde298c620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A derivada da softplus, no entanto, pode ser escrita como 1/1( 1+ 1/exp).\n",
    "@tf.custom_gradient\n",
    "def my_better_softplus(z):\n",
    "    exp = tf.exp(z)\n",
    "    def my_softplus_gradients(grad):\n",
    "        return grad / (1+1/exp)\n",
    "    return tf.math.log(exp+1), my_softplus_gradients\n",
    "\n",
    "# Usando o mesmo valor que na última célula.\n",
    "v1 = tf.Variable(10e10)\n",
    "with tf.GradientTape() as tape:\n",
    "    f = my_better_softplus(v1)\n",
    "    \n",
    "tape.gradient(f, [v1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecb3bdd-ca4a-4164-bde9-6c28f8489a70",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px;'> TensorFlow Functions and Graphs</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Converter funções ordinárias em funções TensorFlow pode causar um ganho de eficiência nas computações realizadas.\n",
    "        </li>\n",
    "        <li> \n",
    "            Curiosidade: Toda função ou classe customizável (métrica, loss, camada) é convertida a uma tf.function.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "84a03a65-720a-4f6e-bf23-cfb5baa0e779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function cube at 0x7facc81d33a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function cube at 0x7facc81d33a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=27.0>"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para realizar essa transformaçõa, use o decorador @tf.function acima de seu método.\n",
    "@tf.function\n",
    "def cube(x):\n",
    "    return x**3\n",
    "\n",
    "# Observe, o valor retornado vem dentro de um tensor.\n",
    "cube(3.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb5e5cd-4a13-4204-acf7-763ca8567fd6",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            A vantagem de gerar tf.function's é a flexibilidade dessas em lidar com tensores de diferentes shapes e data types. No entanto, para cada input de propriedades distintas, um novo grafo computacional é armazenado na memória do computador, consumindo-a.\n",
    "        </li>\n",
    "        <li> \n",
    "            Por outro lado, esse não é exatamente o mesmo caso para valores Python. Um grafo novo é criado a cada input diferente!\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "5c7c8fcb-9ed9-4890-ac32-bcc655565677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float16, numpy=\n",
       "array([[  1.,   8.],\n",
       "       [125., 216.]], dtype=float16)>"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As funções TF podem ser usadas com tensores de qualquer shape e data type.\n",
    "cube(tf.Variable([[1,2], [5,6]], dtype=tf.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "480e9a4a-9c0d-4a3c-8303-5d756e6389c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=1.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.0>)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O TensorFlow vai gerar dois grafos para o código abaixo. Portanto, evite manipular tf.function's com valores Python.\n",
    "cube(1.), cube(2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17311f2-7a90-4e90-82a4-71709cfe5d0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> AutoGraph and Tracing</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Essa seção mostra um pouco como a otimização de funções é feita ao se invocar @tf.function.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00c9736-f16c-489d-9732-e6e558b8af88",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> TF Function Rules</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Evite usar funções de outros módulos (numpy, scipy) ao montar uma tf.function. Isso pode comprometer a performance do código, além de produzir resultados indesejados ao próprio desenvolvedor.\n",
    "        </li>\n",
    "        <li> \n",
    "            Ao criar tf.function's, sempre verifique se existe uma função do TensorFlow que realiza o procedimento que você pretende implantar!\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e71523f-cccc-4045-be67-d7c633bd5615",
   "metadata": {},
   "source": [
    "<p style='color:red'> Chapter 13</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
