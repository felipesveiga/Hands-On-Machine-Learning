{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9e91510-7582-402a-99b6-255ef2f2b365",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'> Training Deep Neural Networks</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cc4a71-2ec3-4d00-8da6-53407feb1b05",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Vanishing/Exploding Gradients</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Em NN muito profundas, as camadas inferiores tendem a ter os seus pesos pouco modificados em cada ciclo do otimizador. Esse fenômeno é conhecido como o desaparecimento de gradientes (Gradient Vanishing).\n",
    "        </li>\n",
    "        <li> \n",
    "            Por outro lado, a seção mais superficial do modelo também é capaz de sofrer incoveniências. É comum os seus pesos terem uma alteração muito grande em cada ciclo, situação nomeada como Gradient Explosion.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b462f015-2d9d-404d-b8c2-64ef2ec66d05",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Glorot and He Initialization</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Xavier Glorot argumenta que as situações descritas podem ser evitadas caso a variância dos inputs e outputs de cada camada seja a mesma. Para que isso possa acontecer, o número de inputs (fan-in) e neurônios (fan-out) deve ser igual.\n",
    "        </li>\n",
    "        <li> \n",
    "            Além disso, a inicialização dos pesos deve ser extraída de uma Distribuição Normal de média 0 e variância ($\\sigma^{2}=\\frac{1}{fan_{avg}}$), ou de uma Uniforme entre -r e +r sendo $r=\\sqrt{\\frac{3}{fan_{avg}}}$\n",
    "            <p style='margin-top:20px'>$$fan_{avg}=\\frac{fan_{in}+fan_{out}}{2}$$</p>\n",
    "        </li>\n",
    "        <li> \n",
    "            Nota: A inicialização LeCun utiliza as mesmas fórmulas que a Glorot, mas trocando $fan_{avg}$ por $fan_{in}$.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51c7049-ce9e-4e43-84d6-587f32d48641",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <img src='initialization1.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d58fe18c-925a-4f22-96fb-a2af1ccf6682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x7f36edbea9d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# É possível definir a inicialização para a camada com 'kernel_initializer'.\n",
    "keras.layers.Dense(30, activation='relu' ,kernel_initializer='he_normal')\n",
    "\n",
    "# A customização pode se tornar um pouco mais específica com os objetos do módulo 'initializers'.\n",
    "dense_init = keras.initializers.VarianceScaling(scale=2, mode='fan_avg', distribution='uniform')\n",
    "keras.layers.Dense(30, activation='relu', kernel_initializer=dense_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc8d70f-86fa-4e68-9c41-f6c3341527bf",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Non Saturating Activation Functions</h3>\n",
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> ReLU</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Foi uma das primeiras funções propostas para substituir a Sigmoid. Tem a vantagem de não saturar com valores positivos e é rápida para se computar.\n",
    "        </li>\n",
    "        <li> \n",
    "            Por outro lado, a ReLU tem inclinação a cometer uma falha grave para learning rates elevadas: matar neurônios. Isso significa que uma boa parte dos TLU's da rede começa a lançar apenas 0 como output.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43de18cb-3320-4654-882c-ffbab61a0dd0",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Leaky RELU</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            A solução para esse infortúnio pode ser providenciada com a Leaky RELU. Com ela, podemos ajustar o parâmetro $\\alpha$, que indica a inclinação da função quando $x<0$.\n",
    "        </li>\n",
    "        <li> \n",
    "            Um paper sugeriu que valores em torno de $\\alpha=0.2$ induziam melhores performances.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1496f5-1295-4694-a9b2-6675ce1247fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando uma LeakyReLU com o módulo 'activations' do Keras.\n",
    "keras.activations.relu(alpha=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232f5470-f417-4eca-ad24-b687c3a1ab48",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Randomized Leaky RELU (RReLU)</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Variação da Leaky ReLU em que $\\alpha$ é definido aleatoriamente durante o treinamento e fixado como um número médio na fase de testes. Aparentemente, funciona como um redutor do risco de overfitting.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476261fd-2a9b-4be5-8dbd-165a5f9a472a",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Parametric Leaky RELU (PReLU)</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Nessa outra variação do Leaky ReLU, $\\alpha$ passa a ter o seu valor ajustado pelo próprio treinamento do modelo. Pode ser excelente em grandes datasets de imagens, mas corre o risco de viciar o modelo em dados menores.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "454e631a-7196-4c00-af8e-08f70f388224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.activation.prelu.PReLU at 0x7f36e3012070>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O PReLU deve ser aplicado com o módulo 'layers'.\n",
    "keras.layers.PReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9e2e12-0e72-4edd-9f0d-59b2f1f70be6",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> ELU</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            A ELU é uma função de ativação recentemente criada com o propósito de superar a ReLU e suas variantes. Podemos afirmar que esse objetivo foi alcançado com um grande sucesso, pois o tempo de treinamento foi reduzido e as redes ELU tiveram uma performance maior no set de teste.\n",
    "        </li>\n",
    "        <li> \n",
    "            O argumento $\\alpha$ indica o valor que ELU tendenciará para argumentos muito baixos.\n",
    "        </li>\n",
    "        <li> \n",
    "            Apenas observe que a fase de teste será mais lenta do que quando essa é feita com a ReLU.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<center> \n",
    "    <img src='elu1.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db4353c8-6eb8-429e-a688-3b8f5cdc5273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ELU com alpha=1')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEICAYAAABCnX+uAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAiVklEQVR4nO3de3hV9Z3v8fc3ITcgAYJJFMIdUaNyjQnao8x4G3S8jfVWIwWLqDNHW3VmrNapdR6nOk5t8Vg7Vg0UxeDlVBxqsXSkynipBAgCogG5ySWCCbeQEBKS7O/5IxtPpCCEbLL23vm8nmc/7Mvav/VJsvPhl7XXXsvcHRERiV0JQQcQEZH2UZGLiMQ4FbmISIxTkYuIxDgVuYhIjFORi4jEOBW5yDEyMzezoZFeVqStVOTSLmb2uZntM7PaVpenwo9NMrP3D/Gch8zsxUPcr7JrBzO7w8yWmFmDmc0IOo90nC5BB5C4cLm7zw86hPAF8G/A3wBpAWeRDqQZucQEM+tnZrPNrMrMdrSa9SeY2b+Y2UYzqzSzF8ysR/ixgeFZ/s1mttnMdpnZ7WZ2lpmtMLPdB8Y5zDoLzOzD8HJbzewpM0s+zLIzzOzXZvaWmdWY2f+Y2YCDFrvQzNaEx/uVmVn4uUPM7O3w17XdzErMrGdbv0fuPtvd/wvY0dbnSmxTkUvUM7NE4PfARmAg0Bd4OfzwpPDlr4HBQHfg4HIuBE4GrgeeAB4ALgROB64zs3GHWXUzcDdwAnA2cAHwD98QtQh4OLz8MqDkoMcvA84ChgPX0TJzBjDgUaAPcBrQD3jowJPM7Pfh8j/U5fffkEc6CRW5RMJ/HVQuUyI8fgEtJffP7r7X3evd/cC29yLgF+6+3t1rgfuBG8ys9WbDh8PP+W9gL/CSu1e6ewXwHjDqUCt19zJ3X+juTe7+OfAMcLjSB5jr7u+6ewMt/1mcbWb9Wj3+7+6+2903Ae8AI8PrWevub7l7g7tXAb9ovR53v8zdex7mctlRfQclrmkbuUTCVW3cRt4EJLW+w8wO3G48xPL9gI3u3nSIx/rQMlM/YCMtr+ucVvd92er6vkPc7n6okGY2jJZSzQe6hsctO9SyYZsPXHH3WjPbGc534P5trZatO7BeM8sB/g9wLpBOywRr1zesR+RrNCOXIGyiZRNJa4NoKfiKQyy/Geh/0Cz7gC+A1tui+4fH+fIQy7bV08Aq4GR3zwB+RMtmkMP5avZtZt2BzHC+I3kEcODM8Hpuar0eM/vDQXsFtb78oe1flsQbFbkcb2Zmqa0vwDzgVDObYGZJZpZJS5m9dphZ9yJgK/DvZtYtPM63wo+9BNxtZoPC5fkI8MphxmmrdGAPUGtmpwJ/f4TlLzWz/xV+Q/RhYKG7bz7Ccw6spxaoNrO+wD+3ftDdL3H37oe5XHJgOTPrEv7+JgKJ4e+T/uruBFTkEglvHDRLfL3VY+fQsvmi9WUncAlwG1AJrAR2c5iidPdm4HJgKC2z+S20vHEJMB2YCbwLbADqgTsj9HX9E3AjUAM8B7xyhOVnAT+h5esbQ8vM+mj8KzAaqAbmArOPJSzwL7R8f+8Lr3tf+D6Jc6YTS4i0X/gDOFvcXcUpHU4zchGRGKciFxGJcdq0IiIS4zQjFxGJcYHsmnTCCSf4wIEDg1i1iEjMKisr2+7uWQffH0iRDxw4kCVLlgSxahGRmGVmGw91vzatiIjEOBW5iEiMU5GLiMQ4FbmISIxTkYuIxLiIFbmZJZrZRzpjiYhIx4rkjPwHQHkExxMRkaMQkSI3s1zgb4HiSIwnIhJv6vY38dDvPqF636FOgtU+kZqRPwHcC4QOt4CZ3WpmS8xsSVVVVYRWKyIS/eobm7n1hTJe+PBzyjbujPj47S5yM7sMqHT3bzqXIe7+rLvnu3t+VtZffMJURCQuNTaHuGPWUt5fu53Hvj2c80/NOfKT2igSM/JvAVeY2efAy8D5ZvZiBMYVEYlpTc0h7np5GfPLK3n4ytO5Nr/fkZ90DNpd5O5+v7vnuvtA4AbgbXc/2lNciYjEpVDIufe1Fcz9eCs/uvRUJpw98LitS/uRi4hEmLvz4zkrmb20grsvHMat5w05ruuL6NEP3X0BsCCSY4qIxBJ356dzyykp3cRt4wbz/QuGHvd1akYuIhJBU9/6jOL3NzDx7AHcN/5UzOy4r1NFLiISIU8vWMeTb6/luvxcfnL56R1S4qAiFxGJiBkfbOCxeau4YkQfHr16OAkJHVPioCIXEWm3VxZv4qE3PuWivBx+ft0IEjuwxEFFLiLSLnOWVXDf7I85b1gWT904iqTEjq9VFbmIyDGat3Ib97y6nIKBmTxz0xhSuiQGkkNFLiJyDN5ZXcmdLy1leG4Ppk06i7TkYEocVOQiIm324bod3D6zjGE56cy4uYDuKRH9SE6bqchFRNqgbOMuJj+/mP6ZXZk5uZAeaUlBR1KRi4gcrZUV1Uyavojs9BRKbikks1ty0JEAFbmIyFFZva2GCdNKyUhLomTKWLIzUoOO9BUVuYjIEayvqqWouJSkxARmTSmkb8+0oCN9jYpcROQbbN5ZR1FxKSF3Sm4pZEDvbkFH+gsqchGRw9hWXU9RcSl7G5qYObmAk3PSg450SCpyEZFD2F7bQFHxQnbUNvD89wo4vU+PoCMdVrA7P4qIRKHddfu5qbiUit37eP7mAkb17xV0pG+kGbmISCs19Y1MnL6I9VV7eXZCPoWDewcd6YhU5CIiYXX7m5g8YwmffLGHXxWN5rxhWUFHOioqchERoL6xmVtfKGPJxp1MvX4kF+XlBB3pqGkbuYh0eo3NIe6YtZT3127nZ9cM5/IRfYKO1CaakYtIp9bUHOKul5cxv7ySh688nWvz+wUdqc1U5CLSaYVCzr2vrWDux1v50aWnMuHsgUFHOiYqchHplNydH89ZyeylFdx94TBuPW9I0JGOmYpcRDodd+enc8spKd3EbeMG8/0LhgYdqV1U5CLS6Ux96zOK39/AxLMHcN/4UzHr2JMlR5qKXEQ6lacXrOPJt9dyXX4uP7n89JgvcVCRi0gnMuODDTw2bxVXjOjDo1cPJyEh9kscVOQi0km8sngTD73xKRfl5fDz60aQGCclDipyEekE5iyr4L7ZH3PesCyeunEUSYnxVX3x9dWIiBxk3spt3PPqcgoGZvLMTWNI6ZIYdKSIU5GLSNx6Z3Uld760lOG5PZg26SzSkuOvxCECRW5mqWa2yMyWm9knZvavkQgmItIeH67bwe0zyxiWk86MmwvonhK/h5aKxFfWAJzv7rVmlgS8b2Z/cPeFERhbRKTNyjbuYvLzi+mf2ZWZkwvpkZYUdKTjqt1F7u4O1IZvJoUv3t5xRUSOxcqKaiZNX0R2egoltxSS2S056EjHXUS2kZtZopktAyqBt9y99BDL3GpmS8xsSVVVVSRWKyLyNau31TBhWikZaUmUTBlLdkZq0JE6RESK3N2b3X0kkAsUmNkZh1jmWXfPd/f8rKzYOOuGiMSO9VW1FBWXkpSYwKwphfTtmRZ0pA4T0b1W3H038A4wPpLjioh8k8076ygqLsXdmTWlkAG9uwUdqUNFYq+VLDPrGb6eBlwErGrvuCIiR2NbdT1FxaXsbWhi5uRChmanBx2pw0Vir5WTgOfNLJGW/xhedfffR2BcEZFvtL22gaLiheyobeDFWwrJ65MRdKRARGKvlRXAqAhkERE5arvr9nNTcSkVu/fx/M0FjOrfK+hIgdEnO0Uk5tTUNzJx+iLWV+3lue/mUzi4d9CRAqUiF5GYUre/ickzlvDJF3v4VdFozj1Ze8GpyEUkZtQ3NnPrC2Us2biTqdeP5KK8nKAjRYX4PfiAiMSVxuYQd8xayvtrt/P4tSO4fESfoCNFDc3IRSTqNTWHuOvlZcwvr+ThK0/nmjG5QUeKKipyEYlqoZBz72srmPvxVh649DQmnD0w6EhRR0UuIlHL3fnxnJXMXlrB3RcOY8p5g4OOFJVU5CISldydn84tp6R0E7eNG8z3LxgadKSopSIXkag09a3PKH5/AxPPHsB940/FLH5OlhxpKnIRiTpPL1jHk2+v5br8XH5y+ekq8SNQkYtIVJnxwQYem7eKK0b04dGrh5OQoBI/EhW5iESNVxZv4qE3PuXivBx+ft0IElXiR0VFLiJRYc6yCu6b/THjhmXxyxtHkZSoejpa+k6JSODmrdzGPa8up2BgJr++aQwpXRKDjhRTVOQiEqh3Vldy50tLGZ7bg2mTziItWSXeVipyEQnMh+t2cPvMMoblpDPj5gK6p+jwT8dCRS4igSjbuIvJzy+mf2ZXZk4upEdaUtCRYpaKXEQ63MqKaiZNX0R2egoltxSS2S056EgxTUUuIh1q9bYaJkwrJSMtiZIpY8nOSA06UsxTkYtIh9mwfS9FxaUkJSYwa0ohfXumBR0pLqjIRaRDbN5ZR9FzC3F3Zk0pZEDvbkFHihsqchE57rZV11NUXEptQxMzJxcyNDs96EhxRUUuIsfV9toGiooXsqO2gee/V0Ben4ygI8Ud7bQpIsfN7rr9TJi2iIrd+3j+5gJG9e8VdKS4pBm5iBwXNfWNTJy+iHWVtTz33XwKB/cOOlLcUpGLSMTV7W9i8owlfPLFHn5VNJpzT84KOlJcU5GLSETVNzZz28wylmzcydTrR3JRXk7QkeKetpGLSMQ0Noe4Y9ZS3luzncevHcHlI/oEHalT0IxcRCKiOeTc9coy5pdX8vBVZ3DNmNygI3UaKnIRabdQyLn3tyuYu2IrD1x6GhPGDgg6UqfS7iI3s35m9o6ZfWpmn5jZDyIRTERig7vz4zkreW3pFu6+cBhTzhscdKROJxLbyJuAf3T3pWaWDpSZ2Vvu/mkExhaRKObuPPJmOSWlm7h93BC+f8HQoCN1Su2ekbv7VndfGr5eA5QDfds7rohEv6nz1/DcexuYdM5Afjj+FMx0suQgRHQbuZkNBEYBpZEcV0Siz9ML1vHkn9ZwXX4uD16WpxIPUMSK3My6A68Bd7n7nkM8fquZLTGzJVVVVZFarYgEYMYHG3hs3iquGNGHR68eTkKCSjxIESlyM0uipcRL3H32oZZx92fdPd/d87Oy9CkvkVj1yuJNPPTGp1ycl8PPrxtBoko8cJHYa8WAaUC5u/+i/ZFEJFrNWVbBfbM/ZtywLH554yiSErUHczSIxE/hW8AE4HwzWxa+XBqBcUUkisxbuY17Xl1O4aBMfn3TGFK6JAYdScLavfuhu78P6G8rkTi2YHUld760lOG5PSieeBZpySrxaKK/i0TkG324bge3zSxjWE46M24uoHuKDtEUbVTkInJYZRt3Mfn5xfTP7MrMyYX0SEsKOpIcgopcRA5pZUU1k36ziOz0FEpuKSSzW3LQkeQwVOQi8hdWb6thwrRSMlKTKJkyluyM1KAjyTdQkYvI12zYvpei4lKSEhOYNaWQvj3Tgo4kR6AiF5GvbN5ZR9FzC3F3Zk0pZEDvbkFHkqOgIhcRALZV11NUXEptQxMzJxcyNDs96EhylLQfkYiwvbaBouKF7Ny7nxdvKSSvT0bQkaQNNCMX6eR21+1nwrRFVOzex/RJZzGyX8+gI0kbqchFOrGa+kYmTl/EuspanvtuPgWDMoOOJMdARS7SSdXtb2LyjCV88sUe/rNoNOeerKOSxioVuUgnVN/YzG0zy1iycSdP3DCSC/Nygo4k7aA3O0U6mcbmEHfMWsp7a7bz+LUjuGx4n6AjSTtpRi7SiTSHnLteWcb88koevuoMrhmTG3QkiQAVuUgnEQo59/52BXNXbOWBS09jwtgBQUeSCFGRi3QC7s6P56zktaVbuPvCYUw5b3DQkSSCVOQicc7deeTNckpKN3H7uCF8/4KhQUeSCFORi8S5qfPX8Nx7G5h0zkB+OP4UWk6zK/FERS4Sx55esI4n/7SG6/JzefCyPJV4nFKRi8SpGR9s4LF5q7hiRB8evXo4CQkq8XilIheJQ68s3sRDb3zKxXk5/Py6ESSqxOOailwkzsxZVsF9sz9m3LAsfnnjKJIS9Wse7/QTFokj81Zu455Xl1M4KJNf3zSGlC6JQUeSDqAiF4kTC1ZXcudLSxme24PiiWeRlqwS7yxU5CJx4MN1O7htZhnDctKZcXMB3VN0GKXOREUuEuPKNu5i8vOL6Z/ZlZmTC+mRlhR0JOlgKnKRGLayoppJv1lEdnoKJbcUktktOehIEgAVuUiMWr2thgnTSslITaJkyliyM1KDjiQBUZGLxKAN2/dSVFxKUmICs6YU0rdnWtCRJEAqcpEYs3lnHUXPLcTdmTWlkAG9uwUdSQKmIheJIduq6ykqLqW2oYmZkwsZmp0edCSJAhEpcjObbmaVZrYyEuOJyF/aXttAUfFCdu7dzwuTC8nrkxF0JIkSkZqRzwDGR2gsETnI7rr9TJi2iIrd+5g+6SxG9usZdCSJIhEpcnd/F9gZibFE5Otq6huZOH0R6ypree67+RQMygw6kkSZDttGbma3mtkSM1tSVVXVUasViWl1+5uYPGMJn3yxh/8sGs25J2cFHUmiUIcVubs/6+757p6flaUXo8iR1Dc2c9vMMpZs3MkTN4zkwrycoCNJlNIBGUSiUGNziDtmLeW9Ndt5/NoRXDa8T9CRJIpp90ORKNMccu56ZRnzyyt5+KozuGZMbtCRJMpFavfDl4APgVPMbIuZTY7EuCKdTSjk3PvbFcxdsZUHLj2NCWMHBB1JYkBENq24+3ciMY5IZ+bu/HjOSl5buoV7LhrGlPMGBx1JYoQ2rYhEAXfnkTfLKSndxO3jhnDn+UODjiQxREUuEgWmzl/Dc+9tYNI5A/nh+FMw08mS5eipyEUC9vSCdTz5pzVcn9+PBy/LU4lLm6nIRQI044MNPDZvFVeO7MMjV59JQoJKXNpORS4SkFcWb+KhNz7l4rwcHr92BIkqcTlGKnKRAMxZVsF9sz9m3LAsfnnjKJIS9asox06vHpEONm/lNu55dTmFgzJ5ZsIYUrokBh1JYpyKXKQDLVhdyZ0vLWV4bg+KJ55FapJKXNpPRS7SQT5ct4PbZpYxLCedGTcX0D1FhzqSyFCRi3SAso27mPz8Ygb07srMyYX0SEsKOpLEERW5yHG2sqKaSb9ZRHZ6Ci9OLiSzW3LQkSTOqMhFjqPV22qYMK2UjNQkSqaMJTsjNehIEodU5CLHyYbteykqLiW5SwKzphTSt2da0JEkTqnIRY6DzTvrKHpuIe5OyS2FDOjdLehIEsdU5CIRtq26nqLiUmobmpg5uZCh2elBR5I4p/2fRCJoe20DRcUL2bl3Py/eUkhen4ygI0knoBm5SITsrtvPhGmLqNi9j+mTzmJkv55BR5JOQkUuEgE19Y1M/M1i1lXW8tx38ykYlBl0JOlEVOQi7VS3v4nJM5bwSUU1/1k0mnNPzgo6knQyKnKRdqhvbOa2mWUs2biTJ24YyYV5OUFHkk5Ib3aKHKPG5hB3zFrKe2u28/i1I7hseJ+gI0knpRm5yDFoDjl3vbKM+eWVPHzVGVwzJjfoSNKJqchF2igUcu797QrmrtjKA5eexoSxA4KOJJ2cilykDdydB3+3kteWbuGei4Yx5bzBQUcSUZGLHC1355E3y3lx4SZuHzeEO88fGnQkEUBFLnLUps5fw3PvbWDSOQP54fhTMNPJkiU6qMhFjsLTC9bx5J/WcH1+Px68LE8lLlFFRS5yBDM+2MBj81Zx5cg+PHL1mSQkqMQluqjIRb7Bq4s389Abn/I3p+fw+LUjSFSJSxRSkYscxpxlFfxw9grGDcviye+MIilRvy4SnfTKFDmEeSu3cc+ryykclMkzE8aQ0iUx6EgihxWRIjez8Wa22szWmtl9kRhTJCgLVldy50tLGZHbg+KJZ5GapBKX6NbuIjezROBXwCVAHvAdM8tr77giQfhw3Q5um1nGKSem85ubC+ieosMRSfSLxIy8AFjr7uvdfT/wMnBlBMYV6VCl63fwvRmLGdC7Ky98r5AeaUlBRxI5KpEo8r7A5la3t4Tv+xozu9XMlpjZkqqqqgisViRyFn++k5tnLKZvrzRKbhlLZrfkoCOJHLUOe7PT3Z9193x3z8/K0oH3JXqUbdzFpOmLOLFHKrOmFJKVnhJ0JJE2iUSRVwD9Wt3ODd8nEvUWrt/BxOmLyM5I5aUpY8lOTw06kkibRaLIFwMnm9kgM0sGbgB+F4FxRY6r+Z9+ycTpi8jJSGHWlEJyMlTiEpva/Za8uzeZ2R3AH4FEYLq7f9LuZCLH0esfbeGf/u8KTu+TwYybC7RNXGJaRPatcvc3gTcjMZbI8eTuFL+3gZ++Wc45Q3rz7HfztYuhxDy9gqXTaGwO8eCcT3hp0SYuOeNEpl4/Uh/2kbigIpdOobqukb8vKePP63bwD381hH+6+BQdxVDihopc4t7ayhpunVnG5p11/PzaEXxbJ0qWOKMil7j2u+VfcN9rK+ianEjJLWMpGJQZdCSRiFORS1xqaGrmp3PLeeHDjeQP6MVTN47mxB7avVDik4pc4s66qlrufmUZK7ZUM+XcQdw7/lQdS1zimopc4oa7M3PhRh55s5zUpER+fdMYxp9xYtCxRI47FbnEhW3V9dz72gre/ayKccOy+Nk1w8nWJzWlk1CRS0wLhZyS0o38x7zVNIZCPHzVGdxU2F9nuZdORUUuMWvVtj3cP/tjPtq0m28N7c2/XXUmg07oFnQskQ6nIpeYU72vkafeXsNvPvicjLQkfnHdCP5uVF/NwqXTUpFLzGhqDjFr0SamvvUZu/c1cu2YXO6/5DR66YBX0smpyCXquTtvr6rk0T+sYm1lLWMHZ/Ivf5vHGX17BB1NJCqoyCVquTsLPqviibc+Y/mWagb27sozE8ZwcV6ONqOItKIil6jj7ry7ZjtT3/qMZZt307dnGo99+0yuHp2rD/aIHIKKXKLG/qYQbyz/guL3N1C+dQ99e6bxyN+dyTVjcknuogIXORwVuQSuuq6RWYs2MePPG/hyTwPDcrrzH98ezpWj+pDSRccLFzkSFbkEwt1Z/PkuXl60ibkfb6WhKcT/GnoCj317OOOGZWkbuEgbqMilQ+2obeD1jyp4adEm1lXtJT2lC9fl9+PGwv6cdlJG0PFEYpKKXI67PfWN/HHlNn63/Av+vG4HzSFndP+e/Mc1w7ls+El0TdbLUKQ99Bskx0X1vkb+57Mq5q74gndWV7G/KURurzRuO28wV47syyknpgcdUSRuqMglYjbu2Mv88kr+VP4lizbspCnkZKWncGNBf64Y2YdR/Xpq27fIcaAil2O2p76R0vU7+fO67by/ZjtrKmsBODm7O7ecO5iL8rIZ2a8XiTrJschxpSKXo1ZT38jyzdV8uH47H6zdwYotuwk5pHRJ4KyBmdxQ0J8LT8tmQG8dgVCkI6nI5ZDcnfXb97J04y6WbtrNR5t2sfrLGtwhMcEY2a8nd/z1UM4ecgKjB/TU/t4iAVKRC43NIdZX7eXTrdV8+sUeyrfWsPKLanbXNQKQntqFUf17Mf6MExndvxejB/Sie4peOiLRQr+NnUhTc4jNu/axrrKW9dtrWVtZS/nWGlZ/WcP+phAAyV0SOPXEdMaffiKj+vdkdP9eDMnqToK2c4tELRV5nGlsDrGtup7Nu+rYsnMfG3bsZX1VLeuq9rJxx14am/2rZXt3S+a0kzKYdM5A8k7KIK9PBoNP6EYXHZhKJKaoyGOIu7OrrpEv99RTWdPAl9X1bNm9jy276tiyax8Vu/axtXofof/f1XRJMAb07sqQrO5ceFoOQ7K6MTirO0OyutGzq07IIBIPVOQBa2wOsbuukV11+9m1d3/Lv3WN7Kht4Ms9DVTW1PPlngaqalqut55RA5jBiRmp5PZKo3BQJrm90sjt1fWrf0/qmapDv4rEuXYVuZldCzwEnAYUuPuSSISKJU3NIfY2NLOnvpHahiZq6puobWikpv7A9SZq65uoqW9kT33TV0V9oLRr6psOO3bPrklkp6eQnZ7K4KxuZKenkpPRcjs7I4Wc9FRO7JGqQ7yKdHLtnZGvBK4GnolAlnZxd5pCTmNziP1NIfY3h2hsdvY3hb5+X1P4/uZm9jeFqG8Msa+xmX37m9nX2Ex9q+t/eTtEfavHauub2NfYfMRsCQbpqUmkp3ahV9dkenVLZmDvri3XuyaT2S2Jnl2TyeyWTM+uSWR2a7k/NUm79InIkbWryN29HOiwj10/+ac1/NdHFeGSDoVL2r+67X7kMY4kwSAtKZG05ERSkxK/dr1HWhInZqSQltRyu3tKF9JTk+ie2oX01C6kp3QJX0+ie0oXMlJbbqclJeqj6SJy3MTUNvLs9BTy+mSQnJhAcpcEklr/m2hfXT9wf+vlksKPf/2+BNKSw2WdlEhqcsvjKl0RiSVHLHIzmw+ceIiHHnD3OUe7IjO7FbgVoH///kcdsLUbCvpzQ8GxPVdEJF4dscjd/cJIrMjdnwWeBcjPz4/ARhAREQHQ7g4iIjGuXUVuZn9nZluAs4G5ZvbHyMQSEZGj1d69Vl4HXo9QFhEROQbatCIiEuNU5CIiMU5FLiIS41TkIiIxzjwSn2tv60rNqoCNx/j0E4DtEYwTKcrVNsrVNsrVNtGaC9qXbYC7Zx18ZyBF3h5mtsTd84POcTDlahvlahvlaptozQXHJ5s2rYiIxDgVuYhIjIvFIn826ACHoVxto1xto1xtE6254Dhki7lt5CIi8nWxOCMXEZFWVOQiIjEupovczP7RzNzMTgg6C4CZPWxmK8xsmZn9t5n1CToTgJn9zMxWhbO9bmY9g84ELSfvNrNPzCxkZoHvKmZm481stZmtNbP7gs4DYGbTzazSzFYGnaU1M+tnZu+Y2afhn+EPgs4EYGapZrbIzJaHc/1r0JlaM7NEM/vIzH4fyXFjtsjNrB9wMbAp6Cyt/Mzdh7v7SOD3wIMB5zngLeAMdx8OfAbcH3CeAw6cvPvdoIOYWSLwK+ASIA/4jpnlBZsKgBnA+KBDHEIT8I/ungeMBf53lHy/GoDz3X0EMBIYb2Zjg430NT8AyiM9aMwWOTAVuBeImndr3X1Pq5vdiJJs7v7f7t4UvrkQyA0yzwHuXu7uq4POEVYArHX39e6+H3gZuDLgTLj7u8DOoHMczN23uvvS8PUaWsqpb7CpwFvUhm8mhS9R8XtoZrnA3wLFkR47JovczK4EKtx9edBZDmZmPzWzzUAR0TMjb+17wB+CDhGF+gKbW93eQhQUUywws4HAKKA04CjAV5svlgGVwFvuHhW5gCdomXyGIj1wu04scTx900mfgR/Rslmlwx3pZNTu/gDwgJndD9wB/CQacoWXeYCWP4lLOiLT0eaS2GVm3YHXgLsO+os0MO7eDIwMvxf0upmd4e6BvsdgZpcBle5eZmZ/Fenxo7bID3fSZzM7ExgELDczaNlMsNTMCtx9W1C5DqEEeJMOKvIj5TKzScBlwAXegR8eiNTJuztABdCv1e3c8H1yGGaWREuJl7j77KDzHMzdd5vZO7S8xxD0m8XfAq4ws0uBVCDDzF5095siMXjMbVpx94/dPdvdB7r7QFr+BB7dESV+JGZ2cqubVwKrgsrSmpmNp+VPuivcvS7oPFFqMXCymQ0ys2TgBuB3AWeKWtYyi5oGlLv7L4LOc4CZZR3YK8vM0oCLiILfQ3e/391zw511A/B2pEocYrDIo9y/m9lKM1tBy6afqNglC3gKSAfeCu8a+eugA0F0nbw7/GbwHcAfaXnj7lV3/ySoPAeY2UvAh8ApZrbFzCYHnSnsW8AE4Pzwa2pZeLYZtJOAd8K/g4tp2UYe0V39opE+oi8iEuM0IxcRiXEqchGRGKciFxGJcSpyEZEYpyIXEYlxKnIRkRinIhcRiXH/D1OoOGzWf6bjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "a = 1 * (np.exp(np.linspace(-4,0, 1001, endpoint=False)) - 1)\n",
    "b = np.linspace(0, 4, 1001)\n",
    "a_b=np.concatenate((a,b))\n",
    "plt.plot(np.linspace(-4,4, 2002), a_b)\n",
    "plt.title('ELU com alpha=1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f11d636-8fbe-45f0-ba84-57fd09fbe418",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> SELU</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            A SELU se propõe a ser a versão escalada da ELU. Tem o potencial de bater todas as outras funções sob as seguintes condições:\n",
    "            <ul style='list-style-type:lower-alpha'> \n",
    "                <li> \n",
    "                    A rede ser inteiramente feita com camadas densas (os neurônios recebem todos os outputs da camada anterior) e consistir em uma Sequential API.\n",
    "                </li>\n",
    "                <li> \n",
    "                    Os inputs estarem normalizados com média 0 e desvio-padrão 1.\n",
    "                </li>\n",
    "                <li> \n",
    "                    A inicialização dos pesos deve ser feita com LeCun normal.\n",
    "                </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li> \n",
    "            Se esses requisitos forem cumpridos, a rede irá se auto-normalizar. Ou seja, os outputs das camadas terão média 0 e std 1.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f12c1ce-3542-4718-ae07-078417026906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x7f36d38dc520>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementando a SELU com a inicialização 'lecun_normal'\n",
    "keras.layers.Dense(45, activation='selu', kernel_initializer='lecun_normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a790d9f7-a8f4-4771-9c9d-1882c95cd57c",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Batch Normalization</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            A Batch Normalization consiste na normalização dos outputs de uma TLU (antes mesmo da aplicação da função de ativação). Funciona como um StandardScaler, do Scikit-Learn.\n",
    "        </li>\n",
    "        <li> \n",
    "            Em treinamento, os batches são normalizados separadamente com as suas respectivas médias e variâncias, por isso, recomenda-se setar um tamanho razoável para eles (mais de 30 instâncias, se possível). Para teste, uma média móvel de todas as médias e desvios-padrões para a dada camada é feita para a normalização dos dados.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<center> \n",
    "    <img src='bn1.png'>\n",
    "</center>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Apenas observe que, após a padronização dos dados à moda StandardScaler, os dados são multiplicados por um fator $\\gamma$ e somados por um $\\beta$. Esses são aprendidos durante o treinamento.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a80904-2af2-4e67-9ca2-d3f785e9a5fd",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Impactos da BN</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            A Batch Normalization é uma outra solução para a questão do desaparecimento/explosão de gradientes.\n",
    "        </li>\n",
    "        <li> \n",
    "            O treinamento é acelerado. Há também a regularização do modelo.\n",
    "        </li>\n",
    "        <li> \n",
    "            A BN torna possível que learning rates maiores alcancem a solução ótima.\n",
    "        </li>\n",
    "        <li> \n",
    "            As previsões podem ser mais devagares com a BN. Caso necessite de estimativas rápidas, recorra primeiro à função de ativação ELU juntamente com a inicialização He.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7867f7-2634-4607-b856-88d7850a18a7",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Implementing Batch Normalization with Keras</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06cd80f6-b7a1-4768-8b5b-b321df6cdf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Os criadores da BN recomendam que ela seja utilizada antes da função de ativação. Por isso, estamos usando TLU's lineares e \n",
    "# 'keras.layers.Activation()'.\n",
    "model = keras.models.Sequential([\n",
    "            keras.layers.Input(shape=[8]),\n",
    "            # Queremos que os inputs sejam normalizados logo de início.\n",
    "            keras.layers.BatchNormalization(),\n",
    "            \n",
    "            # Os dados passarão pelos TLU's sem função de ativação, tendo os seus outputs normalizados.\n",
    "            # Como a BatchNormalization disponibiliza um termo de offset, podemos desconsiderar o uso do parâmetro de bias das camadas.\n",
    "            # Só após isso que a função de ativação será posta em ação.\n",
    "            keras.layers.Dense(90, kernel_initializer='he_normal',use_bias=False),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Activation('elu'),\n",
    "    \n",
    "            keras.layers.Dense(70, kernel_initializer='he_normal',use_bias=False),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Activation('elu'),\n",
    "    \n",
    "            # Normalizaremos as informações também antes da camada de output.\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bdc24a-33bf-48aa-9bb5-46311c1d7b14",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Gradient Clipping</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O Recorte de Gradientes é outra maneira de impedirmos a explosão de gradiente. Há duas maneiras de fazermos isso. \n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0434a5d3-6308-46f3-ad76-6188dacc8d09",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> clipvalue</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             As derivadas parciais do vetor de gradiente serão recortadas caso seus módulos superem \"clipvalue\". Por exemplo, o vetor $\\begin{bmatrix} 10 \\\\ 0.2 \\\\ -5\\end{bmatrix}$ ficará $\\begin{bmatrix} 1 \\\\ 0.2 \\\\ -1\\end{bmatrix}$ caso clipvalue=1.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a64d71c-7f78-4473-b9a4-923438a8ca56",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> clipnorm</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             Observe que, porém, o recorte por clipvalue altera a orientação do vetor de gradiente. Se preferir preservar isso, use a opção clipnorm. \n",
    "        </li>\n",
    "        <li> \n",
    "            Caso ao menos um dos módulos das derivadas direcionais ultrapasse o threshold definido, o vetor inteiro é normalizado pela norma L-2. Por exemplo, o vetor $\\begin{bmatrix} 10\\\\0.2\\\\-5\\end{bmatrix}$ ficará como $\\begin{bmatrix}  0.89428412 \\\\ 0.01788568 \\\\ -0.44714206 \\end{bmatrix}$\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4e541c-16e7-4e24-9012-c62ad8917855",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Reusing Pretrained Layers</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             O treinamento de uma rede neural é algo custoso tanto em termos de tempo, quanto de processamento. Considerando isso, foi criada a possibilidade de usarmos camadas de NN já existentes e inseri-las em nosso modelo. Observe que o uso dessa técnica surte efeitos mais significativos em redes neurais convolucionais profundas. \n",
    "        </li>\n",
    "        <li> \n",
    "            O ideal é que a rede neural da qual herdaremos as camadas tenha sido criada para uma tarefa similar à nossa. Por exemplo, seria interessante coletarmos as hidden layers de um modelo geral de classificação de animais para uma rede de identificação de cães vira-lata (binária). Quanto mais próximo foi o propósito do algoritmo-base do de nosso modelo, mais camadas podemos usar!\n",
    "        </li>\n",
    "        <li> \n",
    "            É importante lembrar que, usualmente, a camada de output do modelo-base não é apropriada à nossa missão. Por isso, considere trocá-la.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fc9b3d-f3fe-4215-8edd-9f69dc81e312",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Conselhos para Transfer Learning</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             Congele os coeficientes das camadas herdadas nas primeiras seções de fitting. Se porventura não obtiver a performance almejada, descongele-os aos poucos.\n",
    "        </li>\n",
    "        <li> \n",
    "            Não use learning rates muito elevadas para não provocar alterações bruscas nos coeficientes das camadas herdadas.\n",
    "        </li>\n",
    "        <li> \n",
    "            Com bastantes dados, podemos descongelar ou criar novas camadas no modelo.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933e7e5c-940f-45d3-9b53-c86cf8f5d2e4",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Transfer Learning With Keras</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             Simularemos o uso do Transfer Learning com o dataset Fashion MNIST. Pegaremos as camadas de uma rede treinada em todo o dataset a fim de criar um modelo que diferencie sandálias de sapatos.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a5ccf64-e1d5-4054-9d90-e41da09c2476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 08:36:04.656135: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /u01/app/oracle/product/11.2.0/xe/lib:/lib:/usr/local/lib:\n",
      "2022-11-25 08:36:04.656164: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "# Carregando os dados.\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a0d2ea9-7fa9-4bd1-9143-7406b4dbae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alterando as escalas das features.\n",
    "X_train_scaled, X_test_scaled = X_train/255, X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93a48e34-3889-4e88-a3dd-eb26e7e3d98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3334/3334 [==============================] - 11s 3ms/step - loss: 0.6419 - val_loss: 0.5807\n",
      "Epoch 2/50\n",
      "3334/3334 [==============================] - 10s 3ms/step - loss: 0.4521 - val_loss: 0.4844\n",
      "Epoch 3/50\n",
      "3334/3334 [==============================] - 10s 3ms/step - loss: 0.4167 - val_loss: 0.4354\n",
      "Epoch 4/50\n",
      "3334/3334 [==============================] - 10s 3ms/step - loss: 0.3940 - val_loss: 0.4323\n",
      "Epoch 5/50\n",
      "3334/3334 [==============================] - 10s 3ms/step - loss: 0.3798 - val_loss: 0.4527\n",
      "Epoch 6/50\n",
      "3334/3334 [==============================] - 10s 3ms/step - loss: 0.3663 - val_loss: 0.3958\n",
      "Epoch 7/50\n",
      "3334/3334 [==============================] - 10s 3ms/step - loss: 0.3560 - val_loss: 0.4123\n",
      "Epoch 8/50\n",
      "3334/3334 [==============================] - 10s 3ms/step - loss: 0.3465 - val_loss: 0.3940\n",
      "Epoch 9/50\n",
      "3334/3334 [==============================] - 10s 3ms/step - loss: 0.3383 - val_loss: 0.3839\n",
      "Epoch 10/50\n",
      "3334/3334 [==============================] - 12s 3ms/step - loss: 0.3317 - val_loss: 0.3937\n",
      "Epoch 11/50\n",
      "3334/3334 [==============================] - 11s 3ms/step - loss: 0.3252 - val_loss: 0.3686\n",
      "Epoch 12/50\n",
      "3334/3334 [==============================] - 11s 3ms/step - loss: 0.3179 - val_loss: 0.3702\n",
      "Epoch 13/50\n",
      "3334/3334 [==============================] - 10s 3ms/step - loss: 0.3125 - val_loss: 0.3590\n",
      "Epoch 14/50\n",
      "3334/3334 [==============================] - 10s 3ms/step - loss: 0.3075 - val_loss: 0.3630\n",
      "Epoch 15/50\n",
      "3334/3334 [==============================] - 10s 3ms/step - loss: 0.3022 - val_loss: 0.4092\n",
      "Epoch 16/50\n",
      "3334/3334 [==============================] - 10s 3ms/step - loss: 0.2977 - val_loss: 0.3709\n",
      "Epoch 17/50\n",
      "3334/3334 [==============================] - 10s 3ms/step - loss: 0.2938 - val_loss: 0.3613\n",
      "Epoch 18/50\n",
      "3334/3334 [==============================] - 10s 3ms/step - loss: 0.2885 - val_loss: 0.3751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8282f51c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agora, treinando uma Sequential API simples.\n",
    "model_A = keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=X_train_scaled.shape[1:]),\n",
    "        keras.layers.Dense(30, activation='elu',\n",
    "                           kernel_initializer=keras.initializers.LecunNormal(seed=42)),\n",
    "\n",
    "        keras.layers.Dense(30, activation='elu',\n",
    "                           kernel_initializer=keras.initializers.LecunNormal(seed=42)),\n",
    "    \n",
    "        keras.layers.Dense(30, activation='elu',\n",
    "                           kernel_initializer=keras.initializers.LecunNormal(seed=42)),\n",
    "    \n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_A.compile(optimizer=keras.optimizers.SGD(), loss='sparse_categorical_crossentropy')\n",
    "model_A.fit(X_train_scaled, y_train, \n",
    "            batch_size=18, epochs=50, callbacks=keras.callbacks.EarlyStopping(patience=5), \n",
    "            validation_data=(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "061a1021-4a1a-4305-a305-dac9bfdb062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora, clonaremos a arquitetura da rede. Isso é importante pois treinar a nossa nova NN com as camadas herdadas mudará o model_A.\n",
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "\n",
    "# 'clone_model' não copia os weights das TLU's. Teremos que fazer isso manualmente\n",
    "model_A_clone.set_weights(model_A.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d3ea5a7c-52fc-453b-a185-ffee1f28f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando nosso novo modelo voltado à noss tarefa binária. Não copiaremos a camada de output, pois essa foi criada para lanãr 10\n",
    "# probabilidades.\n",
    "model_B = keras.models.Sequential(model_A_clone.layers[:-1])\n",
    "\n",
    "# Camada de output com um único neurônio.\n",
    "model_B.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e89e0f2-420d-430a-86bc-a6fb0f774b19",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             Outra coisa necessária a ser feita é impossibilitar o treinamento das camadas herdadas. Isso porque, uma vez que a output layer foi inicializada aleatoriamente, essa cometerá naturalmente equívocos por causa de seus weights mal ajustados.\n",
    "        </li>\n",
    "        <li> \n",
    "            Para impedir que a backpropagation erroneamente culpe os erros da output layer nas camadas herdadas, congelaremos os seus coeficientes.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5a1cdd11-73fb-4921-b100-43eedab82d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "608ccc1b-595c-465a-a732-d3e225b882f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora, compilando o modelo. Como se trata de uma classificação binária, vou alterar a métrica para ROC-AUC.\n",
    "model_B.compile(optimizer=keras.optimizers.SGD(learning_rate=.05), loss=keras.losses.BinaryCrossentropy(),\n",
    "               metrics=keras.metrics.AUC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d3476a8c-d695-43a6-9c54-c0d1c72c770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os datasets apenas para o nosso propósito.\n",
    "train_idx = np.where((y_train==5) | (y_train==7))\n",
    "test_idx = np.where((y_test==5) | (y_test==7))\n",
    "\n",
    "# A classe positiva será a sandália; a negativa, sapato.\n",
    "X_train_B = X_train_scaled[train_idx]\n",
    "y_train_B = (y_train[train_idx]==5).astype('int')\n",
    "\n",
    "X_test_B = X_test_scaled[test_idx]\n",
    "y_test_B = (y_test[test_idx]==5).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "77082259-a3fe-47e1-8bd6-e7528ccd6a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 4s 7ms/step - loss: 0.1098 - auc_1: 0.9954 - val_loss: 0.0865 - val_auc_1: 0.9958\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0636 - auc_1: 0.9976 - val_loss: 0.0836 - val_auc_1: 0.9957\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0592 - auc_1: 0.9976 - val_loss: 0.0829 - val_auc_1: 0.9958\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0574 - auc_1: 0.9976 - val_loss: 0.0825 - val_auc_1: 0.9960\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0563 - auc_1: 0.9976 - val_loss: 0.0827 - val_auc_1: 0.9960\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0556 - auc_1: 0.9976 - val_loss: 0.0828 - val_auc_1: 0.9960\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0552 - auc_1: 0.9976 - val_loss: 0.0829 - val_auc_1: 0.9959\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0547 - auc_1: 0.9975 - val_loss: 0.0830 - val_auc_1: 0.9960\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0544 - auc_1: 0.9976 - val_loss: 0.0830 - val_auc_1: 0.9960\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0540 - auc_1: 0.9976 - val_loss: 0.0832 - val_auc_1: 0.9960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb7cb9958b0>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinando o model_B (apenas camada de output).\n",
    "model_B.fit(X_train_B, y_train_B, epochs=10, validation_data=[X_test_B, y_test_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "be59274b-71b2-4bf5-876b-df2cfa71649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Com a camada de output ajustada, conseguimos fazer um treinamento pleno. Vamos descongelar os weights das hidden layers.\n",
    "for layer in model_B.layers[:-1]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "64118a99-ddf2-4e9a-a5f5-2bc32084b88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "750/750 [==============================] - 7s 7ms/step - loss: 0.0538 - auc_2: 0.9976 - val_loss: 0.0830 - val_auc_2: 0.9961\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0537 - auc_2: 0.9976 - val_loss: 0.0829 - val_auc_2: 0.9961\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0535 - auc_2: 0.9976 - val_loss: 0.0828 - val_auc_2: 0.9960\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0535 - auc_2: 0.9976 - val_loss: 0.0827 - val_auc_2: 0.9960\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0534 - auc_2: 0.9976 - val_loss: 0.0825 - val_auc_2: 0.9961\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0533 - auc_2: 0.9976 - val_loss: 0.0824 - val_auc_2: 0.9961\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0532 - auc_2: 0.9977 - val_loss: 0.0823 - val_auc_2: 0.9961\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0530 - auc_2: 0.9977 - val_loss: 0.0824 - val_auc_2: 0.9961\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0531 - auc_2: 0.9977 - val_loss: 0.0821 - val_auc_2: 0.9961\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0530 - auc_2: 0.9977 - val_loss: 0.0820 - val_auc_2: 0.9961\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0529 - auc_2: 0.9977 - val_loss: 0.0819 - val_auc_2: 0.9961\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0528 - auc_2: 0.9977 - val_loss: 0.0818 - val_auc_2: 0.9961\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0527 - auc_2: 0.9978 - val_loss: 0.0817 - val_auc_2: 0.9961\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0527 - auc_2: 0.9977 - val_loss: 0.0816 - val_auc_2: 0.9961\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0526 - auc_2: 0.9978 - val_loss: 0.0816 - val_auc_2: 0.9961\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0525 - auc_2: 0.9978 - val_loss: 0.0815 - val_auc_2: 0.9961\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0524 - auc_2: 0.9978 - val_loss: 0.0814 - val_auc_2: 0.9961\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0524 - auc_2: 0.9978 - val_loss: 0.0813 - val_auc_2: 0.9961\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0523 - auc_2: 0.9978 - val_loss: 0.0813 - val_auc_2: 0.9961\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0522 - auc_2: 0.9978 - val_loss: 0.0812 - val_auc_2: 0.9962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb7cb79c880>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A fim de preservar os coeficientes das camadas herdadas, use uma learning rate mais baixa.\n",
    "model_B.compile(optimizer=keras.optimizers.SGD(learning_rate=1e-4), loss=keras.losses.BinaryCrossentropy(), \n",
    "                metrics=keras.metrics.AUC())\n",
    "\n",
    "model_B.fit(X_train_B, y_train_B, epochs=20, validation_data=[X_test_B, y_test_B], batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "454bbe18-762f-42d0-90f0-0569cd61e797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.996196"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test_B,model_B.predict(X_test_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f1ab11-0536-4a5b-ae7c-df9e17ffe467",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Unsupervised Pretraining</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             O pretreinamento não-supervisionado consiste em uma estratégia de contigência para situações em que você possui uma dataset com muitas instâncias sem rótulo e Transfer Learning não é possível.\n",
    "        </li>\n",
    "        <li> \n",
    "            O treinamento deve ser feito por camada, congelando todas as demais. A Hidden Layer é fittada com o output de sua predecessora usando um algoritmo de detecção de features (Restricted Boltzmann Machines ou Autoencoders).\n",
    "        </li>\n",
    "        <li> \n",
    "            Ao término desse procedimento, adicione a output layer e faça um treinamento comum em sua rede como um todo com o uso das instâncias rotuladas.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084b664e-a6bc-4007-ba42-275b07de849a",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Pretraining On An Auxiliary Task</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Essa é uma outra estratégia para situações em que possuímos poucas instâncias nomeadas no dataset. É como se fosse um Transfer Learning caseiro.\n",
    "        </li>\n",
    "        <li> \n",
    "            Se dá pela criação de uma primeira rede neural voltada a uma tarefa auxiliar à sua em pauta. Esse modelo aprenderá a reconhecer padrões dos seus dados que poderão ser úteis ao seu projeto principal. Ao final, copie parte de suas camadas mais profundas ao seu modelo principal.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9ef385-ec46-4555-994b-03815c523213",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Faster Optimizers</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             Até agora, o principal otimizador que usamos em modelagem foi a Stochastic Gradient Descent. Apesar de sua popularidade, essa não é a técnica mais veloz para se alcançar as configurações-ótimas. \n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e45bdc-2206-45e2-9836-2fc8fcfe23a2",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Momentum Optimization</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             A Momentum Optmization soma ao $\\theta$ o vetor de momento. A fórmula deste é (k é o número da iteração):\n",
    "            $$\n",
    "                m^{k}=\\beta m^{k-1} - \\eta \\nabla_{\\theta}J(\\theta^{k-1})\n",
    "            $$\n",
    "        </li>\n",
    "        <li> \n",
    "            $\\beta$ servirá como um limitador da influência do vetor de momento anterior, assim como $\\eta$ restringe o valor de $\\nabla_{\\theta}J(\\theta)$.\n",
    "        </li>\n",
    "        <li> \n",
    "            Assim, a atualização dos coeficientes se dará como:\n",
    "            <p style='margin-left:300px'>\n",
    "            $\\theta^{k}=\\theta^{k-1}+m^{k}$ | $\\theta^{k}=\\theta^{k-1}+(\\beta m^{k-1} - \\eta \\nabla_{\\theta}J(\\theta^{k-1}))$\n",
    "            </p>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0aa308-fa7c-4218-8905-c7424e048578",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Análise das Iterações</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f231fe-90a0-414c-a314-27acb719dd62",
   "metadata": {},
   "source": [
    "<h5 style='font-size:25px;font-style:italic;text-decoration:underline'> 1a</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376be79d-061f-49d6-9b57-0523dd48e176",
   "metadata": {},
   "source": [
    "<p style='font-size:20px'> \n",
    "    $m^{1}=\\beta 0 - \\eta \\nabla_{\\theta}J(\\theta^{0})$\n",
    "</p>\n",
    "<p style='font-size:20px'> \n",
    "    $\\theta^{1}=\\theta^{0}+m^{1}=\\theta^{0}- \\eta \\nabla_{\\theta}J(\\theta^{0})$ (Como uma SGD comum)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7485cb3-ddcc-479c-85e6-1ae357c3fd2e",
   "metadata": {},
   "source": [
    "<h5 style='font-size:25px;font-style:italic;text-decoration:underline'> 2a</h5>\n",
    "<p style='font-size:20px'> \n",
    "    $m^{2}=\\beta m^{1} - \\eta \\nabla_{\\theta}J(\\theta^{1})=\\beta (- \\eta \\nabla_{\\theta}J(\\theta^{0})) - \\eta \\nabla_{\\theta}J(\\theta^{1})$\n",
    "</p>\n",
    "<p style='font-size:20px'> \n",
    "    $\\theta^{2}=\\theta^{1}+m^{2}=\\theta^{1}+ \\beta (- \\eta \\nabla_{\\theta}J(\\theta^{0})) - \\eta \\nabla_{\\theta}J(\\theta^{1})$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc6d7e-13eb-42a5-ba3c-64c8da4c1731",
   "metadata": {},
   "source": [
    "<h5 style='font-size:25px;font-style:italic;text-decoration:underline'> 3a</h5>\n",
    "<p style='font-size:20px'> \n",
    "    $m^{3}=\\beta m^{2} - \\eta \\nabla_{\\theta}J(\\theta^{2})=\\beta [\\beta (- \\eta \\nabla_{\\theta}J(\\theta^{0})) - \\eta \\nabla_{\\theta}J(\\theta^{1})] - \\eta \\nabla_{\\theta}J(\\theta^{2})$\n",
    "</p>\n",
    "<p style='font-size:20px'> \n",
    "    $\\theta^{3}=\\theta^{2}+m^{3}=\\theta^{2}+ \\beta [\\beta (- \\eta \\nabla_{\\theta}J(\\theta^{0})) - \\eta \\nabla_{\\theta}J(\\theta^{1})] - \\eta \\nabla_{\\theta}J(\\theta^{2})$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb7f7d-af2d-476e-a3b7-543a75d50815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A implementação da Momentum Optimization se dá com a classe SGD, do módulo 'optimizers' do Keras.\n",
    "keras.optimizers.SGD(learning_rate=1e-4, momentum=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c26666d-1ee8-4580-97ec-327a79e3d882",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Nesterov Accelerated Gradient</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             Yurii Nesterov propôs uma pequena alteração da Momentum Optimization: medimos o vetor de gradiente em $\\theta + \\beta m$. Esse ajuste quase sempre faz o treinamento ser mais rápido do que a última estratégia apresentada.\n",
    "            <div style='margin-left:350px'>\n",
    "                <p> $m^{k+1}=m^{k}-\\eta \\nabla_{\\theta}{J(\\theta^{k}+\\beta m^{k})}$</p>\n",
    "                <p> $\\theta^{k+1}=\\theta^{k}+m^{k+1}$</p>\n",
    "            </div>\n",
    "                </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e0bb2ea2-258b-42de-aa1f-49d288ecff20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizers.optimizer_v2.gradient_descent.SGD at 0x7fb811bdae50>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para usar a NAG, defina o argumento 'nesterov' como True.\n",
    "keras.optimizers.SGD(learning_rate=1e-4, momentum=.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0b35f7-35ea-4c02-b9d3-d622f924febc",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> AdaGrad</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             Todos os algoritmos de otimização vistos até então mantêm a sua $\\eta$ constante com o evoluir do treinamento. Isso pode ser considerado um fator limitador, pois pode nos fazer rodear o ponto do mínimo global várias vezes até que paremos nele. Foi considerando essa situação que a AdaGrad Optimization foi concebida. \n",
    "        </li>\n",
    "        <li> \n",
    "            Com essa, a learning rate é reduzida ao longo das iterações com o objetivo de aterrisarmos no mínimo global mais rapidamente. Seu valor é dividido pelo vetor $\\vec{s}$, que contém a soma do quadrado das derivadas parciais de todas as iterações feitas até o dado momento. Observe que o quociente resultante será um vetor, o que faz com que cada $\\theta$ da rede tenha a sua própria learning rate!\n",
    "        </li>\n",
    "            <div>\n",
    "                <center> $\\theta^{k+1}=\\theta^{k}-\\eta^{k+1}{\\nabla_{\\theta}J(\\theta^{k})}$ </center>\n",
    "                <center> $\\eta^{k+1}=\\frac{\\eta^{k}}{\\sqrt{s^{k+1}+\\epsilon}}$ ($\\epsilon$ é um número positivo pequeno que evita divisões por 0.</center>\n",
    "                <center> $s^{k+1}=s^{k}+\\nabla_{\\theta}J(\\theta^{k})\\odot \\nabla_{\\theta}J(\\theta^{k})$ ($\\odot$ é a multiplicação element-wise)</center>\n",
    "        </div>\n",
    "        <li style='margin-top:10px'> \n",
    "            Apesar de sua estratégia ser interessante, o AdaGrad costuma interromper o treinamento antes de alcançar o mínimo local. Por outro lado, sua lógica baseou a criação de outros otimizadores de maior qualidade.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af66aa16-6b3f-4948-933d-a021b801b884",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> RMSProp</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             Se nos atentarmos às equações da AdaGrad, perceberemos que seu criador poderia ter recorrido a uma estratégia encontrada na Momentum Opt e NAG: o uso de um argumento $\\beta$ que reduz, gradativamente, a influência das derivadas parciais anteriores na geração de $\\theta$. A RMSProp, basicamente, aplica esse ajuste:\n",
    "            <div>    \n",
    "                <center>$\\theta^{k+1}=\\theta^{k}-\\eta^{k+1}\\nabla_{\\theta}J(\\theta^{k})$</center>\n",
    "                <center> $\\eta^{k+1}=\\frac{\\eta^{k}}{\\sqrt{s^{k+1}+\\epsilon}}$</center>\n",
    "                <center> $s^{k+1}=\\beta{s^{k}}+(1-\\beta)\\nabla_{\\theta}{J(\\theta^{k})}\\odot\\nabla_{\\theta}{J(\\theta^{k})}$</center>\n",
    "            </div>\n",
    "        </li>\n",
    "        <li> \n",
    "             O uso de $\\beta$ desacelerará o crescimento de $\\vec{s}$ e, consequentemente, o decaimento de $\\vec{\\eta}.$\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe36aa88-3176-4343-a36d-881b891760c7",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Adam</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             A Adaptive Moment Estimation tenta ser uma combinação da Momentum Optimization e RMSProp. Ou seja, a atualização dos coeficientes ocorre considerando os gradientes anteriores e com uma learning rate adaptativa. A criação dos vetores $\\vec{m}$ e $\\vec{s}$ acontece com betas distintos.\n",
    "            <div>\n",
    "                <center> \n",
    "                        $m^{k+1}=\\beta_{1}m^{k}-(1-\\beta_{1})\\nabla_{\\theta}{J(\\theta^{k})}$\n",
    "                </center>\n",
    "                <center style='margin-top:10px'> \n",
    "                        $\\hat{m}^{k+1}=\\frac{m^{k+1}}{1-\\beta_{1}^{t}}$\n",
    "                </center>\n",
    "                <center style='margin-top:10px'> \n",
    "                        $s^{k+1}=\\beta_{2}s^{k}+(1-\\beta_{2})\\nabla_{\\theta}{J(\\theta^{k})}$\n",
    "                </center>\n",
    "                <center style='margin-top:10px'> \n",
    "                        $\\hat{s}^{k+1}=\\frac{s^{k+1}}{1-\\beta_{2}^{t}}$\n",
    "                </center>\n",
    "                <center style='margin-top:10px'> \n",
    "                        $\\eta^{k+1}=\\frac{\\eta^{k}}{\\sqrt{\\hat{s}^{k+1}+\\epsilon}}$\n",
    "                </center>\n",
    "                <center style='margin-top:10px'> \n",
    "                        $\\theta^{k+1}=\\theta+\\eta^{k+1}\\hat{m}^{k+1}$\n",
    "                </center>\n",
    "            </div>\n",
    "        </li>\n",
    "        <li> \n",
    "            Uma variante interessante de Adam seria a Nadam, que, assim como NAG, computa os gradientes em $\\theta+\\beta\\hat{m}$\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11ea7b2-9263-4d93-b9d3-7ff85e781b41",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Training Sparse Models</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             É possível que precisemos de uma rede neural esparsa (com um número maior de coeficientes 0) por questões de memória, por exemplo. A primeira estratégia que poderíamos pensar seria recorrer à regularização $l1$, mas essa pode não zerar neurônios o bastante.\n",
    "        </li>\n",
    "        <li> \n",
    "            A melhor solução seria usar o otimizador FTRL, desenvolvido por Yurii Nesterov e  colaboradores do Google. Esse possui uma classe pronta no Keras.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bcca37f-7f3d-4af1-bbf0-41843dd74319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizers.optimizer_v2.ftrl.Ftrl at 0x7f7a05929fa0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Otimizador FTRL:\n",
    "keras.optimizers.Ftrl()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce05f307-5399-4c33-b3ac-6d6fcd488e57",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Learning Rate Scheduling</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             Aprenderemos aqui estratégias de alterações da Learning Rate. Acredito que essas são mais apropriadas quando usamos otimizadores que não alteram o seu valor (como SGD ou NAG).\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75ce9b5-0036-442b-964f-a7af67ad1fac",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Power Scheduling</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             A cada s steps (atualizações do gradiente, não epochs), a learning rate é reduzida para $\\frac{\\eta_{0}}{2}$; após mais s steps, para $\\frac{\\eta_{0}}{3}$, e assim por diante.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc63b762-304c-4eed-ad8a-f85211919441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizers.optimizer_v2.gradient_descent.SGD at 0x7f7a04e2afd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Power Scheduling é implementado com o uso de 'decay' - o inverso do número de steps - em qualquer otimizador.\n",
    "keras.optimizers.SGD(.001, momentum=.9, decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b1a3cc-6641-42f2-8a25-669a457caf7d",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Exponential Scheduling</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Propõe a redução exponencial da Learning Rate em função da quantidade de steps realizados. O $\\eta_0$ será multiplicado por um fator $\\alpha$ elevado pelo quociente do número do step atual dividido por um threshold de número de steps t.\n",
    "            <center> \n",
    "                $\\eta(s)=\\eta_{0}\\alpha^{\\frac{s}{t}}$\n",
    "            </center>\n",
    "        </li>\n",
    "        <li> \n",
    "            Por exemplo, podemos usar uma Exponential Scheduling com um $\\eta_0=0.01$, $\\alpha=0.95$ e t=100 steps:\n",
    "            <center> $\\eta(s)=0.01 \\times 0.95^{\\frac{s}{100}}$</center>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da258d53-72f9-4978-b845-864b588b270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential Decay como classe do tf.keras (os schedules não são achados no Keras puro!)\n",
    "keras.optimizers.schedules.ExponentialDecay()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf58126-fcea-42d7-b1c0-0d2dc90d278c",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Piecewise Constant Scheduling</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Estratégia mais manual de escolha e $\\eta$. Escolha o intervalo de steps e a sua respectiva learning rate.\n",
    "        </li>\n",
    "        <li> \n",
    "            Por exemplo, do step 1 ao 500, $\\eta=0.05$; do 501 ao 1000, $\\eta=0.01$; do 1001 até o final, $\\eta=0.005$.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c64c5174-26dd-4871-8907-152da330745a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizers.schedules.learning_rate_schedule.PiecewiseConstantDecay at 0x7f7a04f2b7c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementação da Piecewise Constant Scheduling no Keras.\n",
    "keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=[500, 1000], values=[.05, .01, .005])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7460c18d-77f4-404b-8178-077202ae0dfb",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Performance Scheduling</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Reduza a learning rate atual por um fator $\\alpha$ quando o score de validação não é melhorado por n epochs (não steps)!\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e921da-65de-4b00-aad4-c40611846c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'ReduceLROnPlateau' é um callback que exerce o papel de Performance Scheduling.\n",
    "keras.callbacks.ReduceLROnPlateau()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cfbfe2-6fe8-4fc2-a74f-fbae2c2758f1",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Schedulers Customizáveis</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Se preferir criar um scheduler, gere a sua lógica por meio de uma função e passe-a como argumento do callback LearningRateScheduler.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "108e0d49-70ef-48b6-a086-3240d097a6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.LearningRateScheduler at 0x7f7a04e08cd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_scheduler(lr, epoch):\n",
    "    if epoch<50:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr/5\n",
    "\n",
    "# Criando o callback juntamente com o scheduler.\n",
    "keras.callbacks.LearningRateScheduler(my_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f734c23-04df-4787-8288-d223e9f3d3d2",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Avoiding Overfitting Through Regularization</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             A alta flexibilidade das redes neurais vem com um custo: sua alta propensão a overfitting. Considerando isso, nesta seção, lidaremos com algumas estratégias de regularização.\n",
    "        </li>\n",
    "        <li> \n",
    "            Cabe salientar que nós já aprendemos alguns regularizadores para NN's (Early Stopping e Batch Normalization).\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aa35e7-fded-4c52-ae93-f443d72bafd2",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> $l1$ and $l2$ Regularization</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O Keras nos permite acrescentar as normas $l1$ e $l2$ à função loss.\n",
    "        </li>\n",
    "        <li> \n",
    "            As normas podem ser a respeito:\n",
    "            <ul style='list-style-type:circle'> \n",
    "                <li> \n",
    "                    Dos pesos da hidden layer (chamados também de kernel): kernel_regularizer.\n",
    "                </li>\n",
    "                <li> \n",
    "                    Da bias da hidden layer: bias_regularizer.\n",
    "                </li>\n",
    "                <li> \n",
    "                    Do output da hidden layer: activity_regularizer.\n",
    "                </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2397d1e-d991-4c0a-88b9-a8e5c91f158a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.regularizers.L1L2 at 0x7f79efe75b50>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note, é possível aplicar Elastic Net à função-custo:\n",
    "keras.regularizers.l1_l2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a9fe057-f774-4fa1-bf41-1588e9c76cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montar uma rede neural com todas as estratégias apresentadas até o momento pode deixar o nosso código poluído.\n",
    "# Foi considerando isso que o Aurélien nos aconselhou a usarmos um wrapper de classes - o functools.partial - que encapsula \n",
    "# um objeto parcialmente configurado. Para aplicá-lo na rede neural, basta mencioná-lo.\n",
    "from functools import partial\n",
    "\n",
    "# Criando uma 'Dense' layer pré-definida. Vamos deixar o argumento 'units' em aberto.\n",
    "RegularizedDense = partial(keras.layers.Dense, activation='elu', kernel_initializer='he_normal', \n",
    "                           kernel_regularizer=keras.regularizers.l2(.1))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=[28,28]),\n",
    "        # Agora, mencionando apenas o objeto 'partial' criado.\n",
    "        RegularizedDense(units = 30),\n",
    "        RegularizedDense(units=50),\n",
    "        RegularizedDense(units=50),\n",
    "        RegularizedDense(units=10, activation='softmax', kernel_initializer='glorot_uniform')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bed39c-874c-4723-96a2-1b1694be8598",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Dropout</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             Dropout é uma das técnicas de regularização mais populares em Deep Learning. Consiste em desconsiderar certos neurônios durante um certo step do treinamento dada uma probabilidade 'rate' de isso ocorrer.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4822d0e1-81d5-45d3-aa99-2b8ebc816f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.regularization.dropout.Dropout at 0x7f79efd9adc0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Géron afirma que definindo 'rate'=.5 produz bons resultados.\n",
    "keras.layers.Dropout(rate=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41e5515-feda-4f7f-8e80-31ff0d374dba",
   "metadata": {},
   "source": [
    "<p style='color:red'> Continuar Dropout</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
