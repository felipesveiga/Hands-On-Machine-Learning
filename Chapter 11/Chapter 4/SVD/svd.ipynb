{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "747df13b-e36f-48c2-b540-082fe71107f3",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'> SVD</h1>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Essas anotações surgiram como uma consequência dos primeiros tópicos do capítulo 4. O objetivo aqui é entender a maneira como o objeto LinearRegression obtém os seus coeficietes com o uso de matrizes pseudo-inversas.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5e800f-bd55-4a43-8250-d5a257520e39",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> \n",
    "    <a href='https://www.youtube.com/watch?v=TQvxWaQnrqI&t=445s'>Eigenvectors and Eigenvalues</a>\n",
    "</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Há situações em que, dada uma matriz quadrada A, se a multiplicarmos por um vetor $\\vec{x}$, teremos como resultado esse mesmo vetor multiplicado por um número $\\lambda$.\n",
    "                $$\n",
    "                    A\\vec{x}=\\lambda\\vec{x}\n",
    "                $$\n",
    "        </li>\n",
    "        <li> \n",
    "            Nesse cenário, $\\vec{x}$ é reconhecido como autovetor (Eigenvector) e $\\lambda$ como autovalor (Eigenvalue).\n",
    "        </li>\n",
    "        <li> \n",
    "            <u> Observação</u>: O Eigenvector não pode ser o vetor zero ($\\vec{0}$)\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04571cd8-7786-4806-bfe5-7eaebc408330",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Encontrando os Eigenvalues</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Se subtrairmos $\\lambda \\vec{x}$ em ambos os lados da equação e multiplicarmos esse mesmo termo de subtração no lado esquerdo da equação pela matriz identidade, teremos como resultado $A\\vec{x}-\\lambda I \\vec{x}=\\vec{0}$. Colocando $\\vec{x}$ em evidência:\n",
    "            $$\n",
    "                \\vec{x}(A-\\lambda I)=\\vec{0}\n",
    "            $$\n",
    "        </li>\n",
    "        <li> \n",
    "            Para que essa equação seja plenamente satisfeita sem que $\\vec{x}=\\vec{0}$, a matriz $(A-\\lambda I) $ não pode ser invertível e, portanto, deve ter seu determinante igual a zero!\n",
    "            $$\n",
    "            |A-\\lambda I|=0\n",
    "            $$\n",
    "        </li>\n",
    "        <li> \n",
    "            Resolvendo a equação acima, obtemos os Eigenvalues da matriz A.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7075ed59-ea6a-458e-9aaa-8773bb8da79f",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Encontrando os Eigenvectors</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Tendo os Eigenvalues em mãos, podemos implantá-los em $A-\\lambda I$ e encontrar $\\vec{x}$.\n",
    "        </li>\n",
    "        <li> \n",
    "            O resultado final não será um vetor em si, mas uma infinidade de vetores $\\vec{x}$ cujos valores respeitem as proporções dadas pelos resultados do dot product. Observe a resolução de um problema tendo $\\lambda=3$.\n",
    "        </li>\n",
    "        <img src='eigenvector.png'>\n",
    "        <li> \n",
    "            No caso da imagem, consideramos $x_1=1$ e, portanto, $x_2=2$, mas qualquer vetor $\\begin{bmatrix}x_1\\\\2x_1\\end{bmatrix}$ pode ser considerado um Eigenvector.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61f9a5a8-1456-4778-a34d-38c46a172d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3., -1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1,1],[4,1]])\n",
    "np.linalg.eigvals(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd1e1596-043d-412e-a49d-d93c846d8853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.28978415, -0.95709203],\n",
       "        [-0.95709203,  0.28978415]]),\n",
       " array([4.30277564, 0.69722436]),\n",
       " array([[-0.95709203, -0.28978415],\n",
       "        [ 0.28978415, -0.95709203]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.svd(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eed2d4d5-4b1d-440a-81be-1844da3f4007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.28978415, -0.95709203],\n",
       "        [-0.95709203,  0.28978415]]),\n",
       " array([4.30277564, 0.69722436]),\n",
       " array([[-0.95709203, -0.28978415],\n",
       "        [ 0.28978415, -0.95709203]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.linalg import svd\n",
    "np.linalg.svd(A)\n",
    "svd(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad5976a-ee18-414a-9c6a-ff2c1fad0248",
   "metadata": {},
   "source": [
    "<p style='color:red'>Ver esse<a href='https://www.youtube.com/watch?v=TQvxWaQnrqI&t=445s'> vídeo</a> (6:30)</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
