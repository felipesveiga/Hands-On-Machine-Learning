{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd286178-8a12-439a-a71f-da63dfc95e65",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'> Introduction to Artificial Neural Networks With Keras</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b829b0f-8853-4031-a37d-009f01d2674d",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> The Perceptron</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febf0b2d-3d7a-492a-9afb-9e694abe488d",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> TLU</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Uma Threshold Logic Unit (TLU) é uma estrututa que simula um neurônio. Ela recebe uma série de features e computa a soma ponderada delas (assim como um algoritmo de regressão simples). Mas após o cálculo, a equação é utilizada como argumento de uma função conhecida como step function.\n",
    "        </li>\n",
    "        <li> \n",
    "            Pode ser utilizada para tarefas de classificação binária. Assim como na Regressão Logística, caso o resultado obtido esteja acima de um threshold, a instância é designada à classe positiva; senão, à classe negativa.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<center> \n",
    "    <h1> Estrutura de uma TLU</h1>\n",
    "    <img src='tlu1.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54ee9ec-5ae4-4b66-800f-8e6df13fb189",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <h1> As step functions mais comuns da TLU</h1>\n",
    "    <img src='tlu2.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12996bf-94ed-4310-9f88-c169373767f0",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Perceptron</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Um Perceptron consiste em uma camada de várias TLU's. Caso os neurônios sejam conectados com todos os inputs provenientes do nível anterior, dizemos que a camada em questão é uma <em>fully connected layer.</em>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<center> \n",
    "    <h1> Um Perceptron de 3 TLU's</h1>\n",
    "    <img src='perceptron1.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ada46e6-5721-4164-a576-96b0419da0e7",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O Perceptron acima pode realizar 3 classificações binárias distintas, tornando-o um modelo multioutput.\n",
    "        </li>\n",
    "        <li> \n",
    "            Observe que, além das features, um termo bias (nesse caso, 1) também pode ser inserido como input.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<center> \n",
    "    <img src='perceptron2.png'>\n",
    "</center>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Note como a função de previsão para uma fully conneted layer é muito similar à função afim. A letra $\\phi$ é a função de ativação - no contexto do TLU's, ela é chamada de step function.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3354dd-ce5a-4d04-8e58-09f0ead3aa31",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Durante a fase de treino, os neurônios de input que melhor contribuírem para previsões corretas recebem um maior peso ao alimentarem o TLU de output.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3867454-d312-4bd2-bae1-e6aba03f107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As fronteiras de decisão do objeto Perceptron são lineares. Portanto, não espere grandes resultados em datasets complexos!\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X,y = load_iris(return_X_y=True)\n",
    "X, y = X[:, [2,3]], (y==0).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e18ecab0-4486-4b4b-a584-02035dd90017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O objeto 'Perceptron' admite Early Stopping!\n",
    "from sklearn.metrics import roc_auc_score\n",
    "per_clf = Perceptron(early_stopping=True, n_iter_no_change=8).fit(X_train, y_train)\n",
    "roc_auc_score(y_test, per_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe2b6f7-c060-45e6-920f-aa08ce22ba13",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Multi-Layer Perceptron and Backpropagation</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Considerando o desempenho limitado dos Perceptrons, foram criados os Multi-Layer Perceptrons. Eles possuem uma ou mais camadas de TLU's, conhecidas como hidden layers responsáveis por abastecerem a output layer - que possui o(s) TLU(s) que farão as previsões finais.\n",
    "        </li>\n",
    "        <li> \n",
    "            Todas as camadas dos MLP's são fully connected layers e, com exceção do nível de output, contam com um neurônio de bias.\n",
    "        </li>\n",
    "        <li> \n",
    "            Como os valores são transmitidos das camadas inferiores às superiores (e não vice-versa), a arquitetura de um MLP é classificada como uma Feedforward Neural Network (FNN).\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3108bd9-d960-43ae-ba4f-0b09f70d94e8",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Treinando um MLP</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O fitting de um Multi-Layer Perceptron ocorre de maneira iterativa com mini-batches do set de treino.\n",
    "        </li>\n",
    "        <li> \n",
    "            Cada instância do subconjunto alimenta as hidden layers até que o TLU de output faça uma previsão. O valor lançado é comparado com o verdadeiro rótulo/número, sendo o nível de erro avaliado por uma loss function.\n",
    "        </li>\n",
    "        <li> \n",
    "            Em seguida, é analisado o impacto de cada neurônio nas hidden layers para o erro. Com isso, os pesos de cada conexão são atualizados para a próxima instância.\n",
    "        </li>\n",
    "        <li> \n",
    "            É importante ressaltar que os pesos de cada conexão sejam inicializados de maneira aleatória, sem isso, o processo de treinamento pode não convergir a uma solução aleatória.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab392eed-3cb9-4319-b4a7-4b6e8ddedd29",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Regression MLP's</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O autor oferece aqui algumas dicas de montagem de MLP's em regressões.\n",
    "        </li>\n",
    "        <li>\n",
    "            Colocar uma função de ativação nos neurônios de output não é algo comum, mas caso queira que os valores previstos sejam sempre positivos, podemos recorrer ao uso da ReLU ou softplus. Se desejar que os outputs caiam dentro de um certo intervalo numérico, use a Logistic Function ou Hyperbolic Tangent Function (não se esqueça de atualizar os valores-alvo dentro do intervalo requerido [0-1] para logística e [-1,1] para hiperbólica).\n",
    "        </li>\n",
    "        <li> \n",
    "            Com relação à loss function, busque usar o Mean Absolute Error caso o dataset tenha outliers. Além disso, a Hubber Loss pode ser uma opção intermediária entre o MAE e o MSE, tendo menor sensibilidade a outliers, uma alta taxa de precisão e de convergência.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9324d644-b9dc-4433-9c32-77e0cc5e5842",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Classification MLP's</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Com relação a classificações, os neurônios de output recebem uma Regressão Logística (binárias uni ou multiouput), ou uma softmax (multi-class uni ou multioutput) para computar as probabilidades de classe.\n",
    "        </li>\n",
    "        <li> \n",
    "            Em classificações binárias, um neurônio de output para cada condição deve existir; para as multi-classe, um neurônio terá que existir para cada categoria.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f551aecd-9722-4094-90ad-b10f1c4e33f4",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Installing TensorFlow 2</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f422c10a-94bd-4ab3-ad17-85a8d378ad34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.9.1', '2.9.0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.__version__, keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d717b1-93ce-4158-8515-bc9525ef1872",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Building an Image Classifier Using the Sequential API</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Iremos aqui utilizar um dataset para classificação de imagens mais sofisticado do que o MNIST. Esse, o Fashion MNIST, contém imagens sobre peças de vestuário.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85d8d55-0bd7-4baf-9a8d-a9abd9245cf7",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Using Keras to Load the Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0402ecd5-868d-4db8-bd63-646d56c5539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataset.\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "# Segregando os dados de treino e teste (é importante que os X's e y's estejam entre parênteses).\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Agora, iremos criar o set de validação. Vamos aproveitar e normalizar os dados.\n",
    "X_valid, X_train = X_train_full[:5000]/255, X_train_full[5000:]/255\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "# Agora, daremos um nome inteligível às classes-alvo.\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8179f4d-17b9-4a31-a770-ad6cb13a6018",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Creating the Model Using the Sequential API</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Nosso primeiro modelo no TensorFlow será um MLP de duas hidden layers.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e2a87e23-3b2d-4fc6-b237-bc45cda7b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A API Sequential permitirá empilharmos as camadas de TLU's.\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Agora, adionaremos as camadas de TLU's.\n",
    "\n",
    "# A camada 'Flatten' basicamente planifica o array dos dados (de 28x28 para 784x1).\n",
    "# Alternativamente, poderíamos ter adicionado um 'keras.layers.InputLayer(input_shape=[28,28])'.\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "\n",
    "# Nossa rede neural terá duas hidden layers de tamanhos distintos; ambas com uma relu como activation function.\n",
    "model.add(keras.layers.Dense(300, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "\n",
    "# Por se tratar de uma tarefa para classificação múltipla, teremos que criar 10 TLU's e definir 'softmax' como função de \n",
    "# ativação na camada para outputs.\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Nota: poderíamos ter definido activation=keras.activations.relu, por exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "852f8827-7d01-4566-aaf3-f2dd968a8ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Também conseguiríamos construir a rede neural por meio de uma lista de camadas.\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, activation=keras.activations.relu),\n",
    "    keras.layers.Dense(100, activation = keras.activations.relu),\n",
    "    keras.layers.Dense(10, activation=keras.activations.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "39fa9442-2578-4fea-b2d1-1d51614fc83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 'summary' lança um relatório sobre as camadas do modelo e seus parâmetros.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0ba4e1-2282-4dcd-afd0-c4a16a25bf4b",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Note a tremenda quantidade de parâmetros que nosso modelo tem. Apesar de isso conferir bastante flexibilidade no seu treinamento, ele pode sofrer overfitting.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3b98872e-b215-47c6-8f08-dee5d9989eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten_4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x7f919d1554c0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O atributo 'layers' menciona todas as camadas do modelo.\n",
    "print(model.layers[0].name)\n",
    "\n",
    "# Para obter uma camada em específico, use 'get_layer'.\n",
    "dense_21 = model.get_layer('dense_21')\n",
    "dense_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51802bb9-ffe8-487f-bcef-e564394761e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "# É possível visualizar a nossa rede com o seguinte método\n",
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab14cf3-420f-409b-8e25-15fec524a137",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Weights e Biases</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Como já espeficiamos o formato do input na primeira camada, o modelo já inicializou os pesos de conexões e os termos de bias.\n",
    "        </li>\n",
    "        <li> \n",
    "            Caso queira uma outra estratégia na inicialização, procure explorar os argumentos <em> kernel_initializer</em> e <em> bias_initializer</em>, que serão ensinados no próximo capítulo!\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f42b2cf3-18d1-499c-a282-1aac054a4b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0552734  -0.01370593  0.00293531 ...  0.05770957  0.01238564\n",
      "   0.02020808]\n",
      " [-0.05668053  0.07336296 -0.0106301  ... -0.06688693 -0.04526081\n",
      "  -0.02096421]\n",
      " [ 0.01877947  0.02175879 -0.01822219 ... -0.04045416  0.03780955\n",
      "  -0.07247542]\n",
      " ...\n",
      " [-0.0512436  -0.07093383 -0.06993344 ... -0.0512969  -0.00860279\n",
      "   0.00362902]\n",
      " [-0.02233877  0.04725705 -0.04704604 ...  0.05243443  0.04636137\n",
      "   0.0721141 ]\n",
      " [ 0.0703267   0.05418946  0.02972484 ... -0.04649205  0.02327072\n",
      "  -0.06621653]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Como já espeficiamos o formato do input na primeira camada, o modelo já inicializou os pesos de conexões e os termos de bias.\n",
    "\n",
    "# Quais são os weights e biases da camada 'dense_21'?\n",
    "weights, bias = dense_21.get_weights()\n",
    "print(weights)\n",
    "\n",
    "# Veja que todos os biases foram criados como 0.\n",
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89abcdc7-d573-403e-8930-e7d4f190f0b3",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Compiling the Model</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Está na hora de definirmos certas configurações voltadas à fase de treino.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c43b2884-625d-49f5-8927-fb9fab99ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b7de64-2bc8-48f9-b7d4-7cd6fb362584",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Dicas de Compiling</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Para classificações multi-classe com um único output, defina a 'loss' como <em> sparse_categorical_crossentropy</em>; caso o output da classificação multi-classe seja as probabilidades dos rótulos (ex: [0, 0, 0, 1]), 'loss' deverá ser <em> categorical_crossentropy</em>; por último, em classificações binárias (sejam elas uni ou multioutput), 'loss' será <em> binary_crossentropy</em>.\n",
    "        </li>\n",
    "        <li> \n",
    "            Se quiser aplicar um One-Hot Encoding na coluna de target-variables, use <em> keras.utils.to_categorical()</em>.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8726c0-a6d8-4a3e-9077-eaba1638073d",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Training and Evaluating the Model</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O treinamento se assemelha com o do Scikit-Learn, mas como o Keras é uma arquitetura voltada exclusivamente a redes neurais, seu método fit contém alguna parâmetros com foco nesse tipo de modelo.\n",
    "        </li>\n",
    "        <li> \n",
    "            Epochs consiste no treinamento do modelo com uma certa quantidade de batches. Podemos definir quantos desses batches participarão de cada epoch com \"steps_per_epoch\". É possível, ainda, escolher a quantidade de instâncias contidas em cada batch.\n",
    "        </li>\n",
    "        <li> \n",
    "            Importante! Caso \"epoch\" não seja definido, ele será setado a 1, o que não é benéfico para o desempenho do modelo.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a64d630d-b574-4406-bdae-a303802c7e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 113ms/step - loss: 0.7289 - accuracy: 0.7728 - val_loss: 0.7206 - val_accuracy: 0.7724\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.6932 - accuracy: 0.7880 - val_loss: 0.7195 - val_accuracy: 0.7638\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.7179 - accuracy: 0.7536 - val_loss: 0.7156 - val_accuracy: 0.7706\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.7352 - accuracy: 0.7688 - val_loss: 0.7129 - val_accuracy: 0.7706\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.7241 - accuracy: 0.7656 - val_loss: 0.7083 - val_accuracy: 0.7680\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.7315 - accuracy: 0.7472 - val_loss: 0.7087 - val_accuracy: 0.7668\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.7327 - accuracy: 0.7536 - val_loss: 0.7063 - val_accuracy: 0.7674\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.7281 - accuracy: 0.7544 - val_loss: 0.7005 - val_accuracy: 0.7718\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.7403 - accuracy: 0.7560 - val_loss: 0.6983 - val_accuracy: 0.7728\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.7005 - accuracy: 0.7688 - val_loss: 0.6978 - val_accuracy: 0.7740\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.7273 - accuracy: 0.7744 - val_loss: 0.6964 - val_accuracy: 0.7690\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.7269 - accuracy: 0.7616 - val_loss: 0.6937 - val_accuracy: 0.7770\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.7003 - accuracy: 0.7832 - val_loss: 0.6902 - val_accuracy: 0.7766\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.7008 - accuracy: 0.7816 - val_loss: 0.6890 - val_accuracy: 0.7774\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 115ms/step - loss: 0.7425 - accuracy: 0.7576 - val_loss: 0.6876 - val_accuracy: 0.7822\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.6813 - accuracy: 0.7744 - val_loss: 0.6858 - val_accuracy: 0.7738\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.6564 - accuracy: 0.7920 - val_loss: 0.6831 - val_accuracy: 0.7790\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 110ms/step - loss: 0.6777 - accuracy: 0.7800 - val_loss: 0.6809 - val_accuracy: 0.7738\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.7113 - accuracy: 0.7544 - val_loss: 0.6777 - val_accuracy: 0.7810\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.7260 - accuracy: 0.7640 - val_loss: 0.6759 - val_accuracy: 0.7830\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 108ms/step - loss: 0.7099 - accuracy: 0.7680 - val_loss: 0.6762 - val_accuracy: 0.7790\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.6661 - accuracy: 0.7856 - val_loss: 0.6764 - val_accuracy: 0.7758\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.6810 - accuracy: 0.7832 - val_loss: 0.6743 - val_accuracy: 0.7828\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.7001 - accuracy: 0.7624 - val_loss: 0.6693 - val_accuracy: 0.7852\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 107ms/step - loss: 0.6761 - accuracy: 0.7840 - val_loss: 0.6674 - val_accuracy: 0.7852\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6851 - accuracy: 0.7800 - val_loss: 0.6641 - val_accuracy: 0.7850\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.6914 - accuracy: 0.7784 - val_loss: 0.6647 - val_accuracy: 0.7852\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.7097 - accuracy: 0.7560 - val_loss: 0.6621 - val_accuracy: 0.7862\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.6719 - accuracy: 0.7784 - val_loss: 0.6591 - val_accuracy: 0.7852\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.6685 - accuracy: 0.7712 - val_loss: 0.6583 - val_accuracy: 0.7838\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.6715 - accuracy: 0.7784 - val_loss: 0.6559 - val_accuracy: 0.7850\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.6625 - accuracy: 0.7680 - val_loss: 0.6555 - val_accuracy: 0.7850\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.6589 - accuracy: 0.7936 - val_loss: 0.6577 - val_accuracy: 0.7792\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.6553 - accuracy: 0.7624 - val_loss: 0.6523 - val_accuracy: 0.7876\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.6239 - accuracy: 0.8000 - val_loss: 0.6587 - val_accuracy: 0.7804\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6808 - accuracy: 0.7800 - val_loss: 0.6515 - val_accuracy: 0.7886\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.6583 - accuracy: 0.7776 - val_loss: 0.6481 - val_accuracy: 0.7894\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.6571 - accuracy: 0.7880 - val_loss: 0.6486 - val_accuracy: 0.7892\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.6381 - accuracy: 0.7928 - val_loss: 0.6478 - val_accuracy: 0.7828\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.6747 - accuracy: 0.7672 - val_loss: 0.6463 - val_accuracy: 0.7912\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.6478 - accuracy: 0.7840 - val_loss: 0.6398 - val_accuracy: 0.7956\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.6981 - accuracy: 0.7512 - val_loss: 0.6413 - val_accuracy: 0.7914\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6538 - accuracy: 0.7824 - val_loss: 0.6414 - val_accuracy: 0.7842\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.7119 - accuracy: 0.7680 - val_loss: 0.6365 - val_accuracy: 0.7990\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.6298 - accuracy: 0.8016 - val_loss: 0.6351 - val_accuracy: 0.7960\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.6312 - accuracy: 0.7944 - val_loss: 0.6368 - val_accuracy: 0.7930\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.6707 - accuracy: 0.7624 - val_loss: 0.6373 - val_accuracy: 0.7936\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.6494 - accuracy: 0.7896 - val_loss: 0.6329 - val_accuracy: 0.7928\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.6295 - accuracy: 0.7992 - val_loss: 0.6316 - val_accuracy: 0.7950\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.6375 - accuracy: 0.7904 - val_loss: 0.6291 - val_accuracy: 0.7924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f919b5b8d90>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finalmente: treinando a rede neural!\n",
    "model.fit(X_train, y_train, batch_size=250, steps_per_epoch=5, \n",
    "          epochs=50, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad483b-99b4-4a2d-88ff-b32405571fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv /Users/felipeveiga/Desktop/Screen\\ Shot\\ 2022-07-26\\ at\\ 08.44.52.png ./perceptron2.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cb0468-948d-483d-98d2-281ff88808aa",
   "metadata": {},
   "source": [
    "<p style='color:red'> Trecho grifado página (p.300).</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
