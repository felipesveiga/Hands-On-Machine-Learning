{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81163af5-a53e-4101-9c0e-0599011a534f",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'> Training Models</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ab8629-613e-45d2-85ed-d7916e883b65",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px;'> Ajuste de modelos</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Neste capítulo, aprenderemos a ajustar os parâmetros de modelos, a começar pela Regressão Linear.\n",
    "        </li>\n",
    "        <li> \n",
    "            Com relação a ela, podemos tuná-la com o uso de uma equação que, prontamente, retorna os parâmetros que minimizam a função de custo. Ou, somos capazes também de usar uma abordagem conhecida como Gradient Descent, que iterativamente, modifica esses argumentos até que a função-custo seja a menor possível.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e455c610-127f-4595-8543-d1749fe643d8",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px;'> Linear Regression</h2>\n",
    "<center>\n",
    "    <h1> Forma Vetorizada</h1>\n",
    "    <img src='linreg2.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ff62a7-a1c1-4932-ba2c-905926e03d9c",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Lembrando que uma das métricas mais utilizadas é a soma dos erros elevados ao quadrado do modelo (MSE).\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<center> \n",
    "    <h1> Fórmula Vetorizada do MSE</h1>\n",
    "    <img src='mse.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4590ce11-d9c0-4a6d-b4b0-b4838dcba3fd",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> The Normal Equation</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            A Normal Equation é aquela responsável por definir os coeficientes da Regressão Linear.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<center> \n",
    "    <h1> Fórmula da Normal Equation</h1>\n",
    "    <img src='normalequation.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8f20fb-17f9-42bc-97fa-e49833d58126",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Gradient Descent</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Como dito no início, o Gradient Descent, ajusta, iterativamente, os coeficientes da regressão até que a função de custo (por exemplo, o MSE) chegue a um valor mínimo.\n",
    "        </li>\n",
    "        <li>\n",
    "            Os coeficientes recebem valores aleatórios de início, e eles são melhorados de acordo com uma learning rate definida. No entanto, dar um valor muito alto a ela pode fazer o modelo adquirir coeficientes inadequados.\n",
    "        </li>\n",
    "        <li> \n",
    "            Ademais, o autor recomenda que nós coloquemos todas as features dentro de uma mesma escala. Essa prática faz com que menos iterações sejam necessárias para que o valor mínimo da função-custo seja alcançado.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "<center> \n",
    "    <h1> O impacto de diferentes Learning Rates em uma Regressão</h1>\n",
    "    <img src='learning_rate1.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17fdc1e-e975-4367-a26a-dcc14f3805aa",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Batch Gradient Descent</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Bastante eficiente em treinamentos de datasets com muitas features. No entanto, perde eficiência conforme o número de instâncias aumenta!\n",
    "        </li>\n",
    "        <li> \n",
    "            Sua learning rate adequada pode ser descoberta com o GridSearch. \n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123251a5-203a-4122-a3b7-931a28bfe4f9",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Stochastic Gradient Descent</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Treinamento mais veloz em datasets grandes, mas peca em encontrar o valor-ótimo dos coeficientes.\n",
    "        </li>\n",
    "        <li> \n",
    "            Uma maneira que minimiza esse problema é o ajuste da learning rate periodicamente durante as iterações.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38296da3-6ff8-4440-ac13-9aca532cfca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41.74109964] [-3.33178376e-07]\n"
     ]
    }
   ],
   "source": [
    "# Fazendo uma regressão com o SGDRegressor.\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "dataset = make_regression(n_samples=100, n_features=1, random_state=42)\n",
    "X = dataset[0]\n",
    "y = dataset[1]\n",
    "\n",
    "# O regressor fará 1000 (max_iter) iterações para descobrir os coeficientes adequados.\n",
    "# A learning rate inicial (eta0) é 1%.\n",
    "# A função de custo deve ter uma perda de menor do que 1e-3 (tol) por 5 iterações (n_iter_no_change) para que o processo de treinamento\n",
    "# termine antes.\n",
    "sgd_reg=SGDRegressor(max_iter=1000, n_iter_no_change=5,tol=1e-3, penalty=None, eta0=0.1)\n",
    "sgd_reg.fit(X, y)\n",
    "\n",
    "# Inclinação da curva e ponto de interceptação.\n",
    "print(sgd_reg.coef_, sgd_reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59f7d8e-3d2f-4260-94a9-c70e94c8a87f",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Mini-batch Gradient Descent</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Este algoritmo de treinamento tem uma estratégia considerada como um meio-termo em comparação com o Batch Gradient Descent e o Stochastic Gradient Descent.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90686fb-50cb-457e-8391-0a3f0484ea9e",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <h1> Tabela-resumo dos algoritmos de regressão</h1>\n",
    "    <img src='gradient_table.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bce8924-2cdc-481d-bdb6-c8c95aa7f38a",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Polynomial Regression</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72a2663-026f-4a11-9ef8-625a6886c960",
   "metadata": {},
   "source": [
    "<p style='color:red'> Fazer o SGDRegressor</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9bc8aaf1-e9fb-48a6-a430-464d9fc156d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv  /Users/felipeveiga/Desktop/Screen\\ Shot\\ 2022-05-14\\ at\\ 16.24.04.png ./gradient_table.png"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
